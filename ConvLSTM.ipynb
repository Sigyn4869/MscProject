{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ConvLSTM Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "891711670cebda49"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载 X 数组\n",
    "X_loaded = np.load('X_array.npy')\n",
    "\n",
    "# 加载 Y 数据\n",
    "Y_loaded = pd.read_pickle('Y_series.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T01:19:39.705970Z",
     "start_time": "2024-08-17T01:19:36.029153Z"
    }
   },
   "id": "221e3d33bc4180aa",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(400, 400, 5)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_loaded.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T01:19:39.714663Z",
     "start_time": "2024-08-17T01:19:39.708053Z"
    }
   },
   "id": "2f77610f7b57e6c7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(1795,)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_loaded.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T01:19:39.722362Z",
     "start_time": "2024-08-17T01:19:39.715664Z"
    }
   },
   "id": "ad419c2ac13a789",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# 假设 X_original 是形状为 [400, 400, 5] 的空间数据\n",
    "# 假设 Y_original 是形状为 [1795,] 的温度时间序列数据\n",
    "X_original = X_loaded  # 形状: [400, 400, 5]\n",
    "Y_original = Y_loaded  # 形状: [1795,]\n",
    "\n",
    "seq_length = 20  # 设定时间序列的长度\n",
    "\n",
    "# 将时间序列拆分为输入序列和预测值 (滑动窗口方法)\n",
    "def create_sequences(data, seq_length):\n",
    "    X_seq = []\n",
    "    Y_seq = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X_seq.append(data[i:i+seq_length])  # 输入序列：长度为 seq_length 的窗口\n",
    "        Y_seq.append(data[i+seq_length])  # 目标：下一个时间步\n",
    "    return np.array(X_seq), np.array(Y_seq)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T01:19:40.938060Z",
     "start_time": "2024-08-17T01:19:40.934606Z"
    }
   },
   "id": "2b659e4761b78955",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 拆分时间序列数据\n",
    "Y_seq, Y_target = create_sequences(Y_original, seq_length)\n",
    "Y_seq = np.expand_dims(Y_seq, axis=-1)  # [1795-seq_length, seq_length, 1] -> [1775, 20, 1]\n",
    "Y_target = np.expand_dims(Y_target, axis=-1)  # [1795-seq_length, 1] -> [1775, 1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T01:19:46.023649Z",
     "start_time": "2024-08-17T01:19:45.979176Z"
    }
   },
   "id": "72ff16167b9735d5",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 转换为 PyTorch 张量\n",
    "X_land = torch.tensor(X_original, dtype=torch.float32).unsqueeze(0).repeat(len(Y_seq), 1, 1, 1)  # 形状 [1775, 400, 400, 5]\n",
    "Y_seq = torch.tensor(Y_seq, dtype=torch.float32)  # 形状 [1775, 20, 1]\n",
    "Y_target = torch.tensor(Y_target, dtype=torch.float32)  # 形状 [1775, 1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T01:20:41.879501Z",
     "start_time": "2024-08-17T01:20:40.836743Z"
    }
   },
   "id": "b1d768cf7bc943f8",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1775, 400, 400, 5]),\n torch.Size([1775, 20, 1]),\n torch.Size([1775, 1]))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_land.shape, Y_seq.shape, Y_target.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T01:20:42.300900Z",
     "start_time": "2024-08-17T01:20:42.286304Z"
    }
   },
   "id": "e79c6b7653535624",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 调整 X_land 的形状以适应 ConvLSTM 的输入格式\n",
    "X_land = X_land.permute(0, 3, 1, 2).unsqueeze(1).repeat(1, seq_length, 1, 1, 1)  # 形状 [1775, 20, 5, 400, 400]\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-08-17T01:21:00.809378Z"
    }
   },
   "id": "63bb8c706b8c50fa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1775, 400, 400, 5])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_land.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T01:20:57.222017Z",
     "start_time": "2024-08-17T01:20:57.218243Z"
    }
   },
   "id": "8c4eaacba4cf3543",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 创建 DataLoader\n",
    "dataset = TensorDataset(X_land, Y_seq, Y_target)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T01:18:48.592721Z"
    }
   },
   "id": "df3462baf1773df"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# 假设 X_original 是形状为 [400, 400, 5] 的空间数据\n",
    "# 假设 Y_original 是形状为 [1795,] 的温度时间序列数据\n",
    "X_original = X_loaded\n",
    "Y_original = Y_loaded\n",
    "\n",
    "seq_length = 20  # 设定时间序列的长度\n",
    "\n",
    "# 将时间序列拆分为输入序列和预测值\n",
    "def create_sequences(data, seq_length):\n",
    "    X_seq = []\n",
    "    Y_seq = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X_seq.append(data[i:i+seq_length])\n",
    "        Y_seq.append(data[i+seq_length])\n",
    "    return np.array(X_seq), np.array(Y_seq)\n",
    "\n",
    "# 拆分时间序列数据\n",
    "Y_seq, Y_target = create_sequences(Y_original, seq_length)\n",
    "Y_seq = np.expand_dims(Y_seq, axis=-1)  # [1795-seq_length, seq_length, 1]\n",
    "Y_target = np.expand_dims(Y_target, axis=-1)  # [1795-seq_length, 1]\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "X_land = torch.tensor(X_original, dtype=torch.float32).unsqueeze(0).repeat(Y_seq.shape[0], 1, 1, 1)\n",
    "Y_seq = torch.tensor(Y_seq, dtype=torch.float32)\n",
    "Y_target = torch.tensor(Y_target, dtype=torch.float32)\n",
    "\n",
    "# 调整 X_land 的形状以适应 ConvLSTM 的输入格式\n",
    "X_land = X_land.permute(0, 3, 1, 2).unsqueeze(1)  # 变成 (batch_size, seq_length, channels, height, width)\n",
    "\n",
    "# 创建 DataLoader\n",
    "dataset = TensorDataset(X_land, Y_seq, Y_target)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T00:58:33.370082Z",
     "start_time": "2024-08-17T00:58:32.383174Z"
    }
   },
   "id": "b4cf70e66a16b322",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def inspect_first_and_last_batch(dataloader):\n",
    "    \"\"\"\n",
    "    只检查并打印 DataLoader 中第一批和最后一批的数据形状和批大小。\n",
    "    \n",
    "    参数:\n",
    "    dataloader (DataLoader): PyTorch 的 DataLoader 对象。\n",
    "    \n",
    "    返回:\n",
    "    None: 直接打印信息。\n",
    "    \"\"\"\n",
    "    total_batches = len(dataloader)\n",
    "    first_batch = None\n",
    "    last_batch = None\n",
    "    \n",
    "    print(f\"Total Batches: {total_batches}\")\n",
    "\n",
    "    for batch_idx, (X, Y_seq, Y_target) in enumerate(dataloader):\n",
    "        if batch_idx == 0:\n",
    "            first_batch = (X, Y_seq, Y_target)\n",
    "        if batch_idx == total_batches - 1:\n",
    "            last_batch = (X, Y_seq, Y_target)\n",
    "\n",
    "    if first_batch:\n",
    "        X, Y_seq, Y_target = first_batch\n",
    "        print(f\"First Batch (Batch 1):\")\n",
    "        print(f\"Batch size (X): {X.shape[0]}\")\n",
    "        print(f\"X shape: {X.shape}\")\n",
    "        print(f\"Y_seq shape: {Y_seq.shape}\")\n",
    "        print(f\"Y_target shape: {Y_target.shape}\")\n",
    "\n",
    "    if last_batch:\n",
    "        X, Y_seq, Y_target = last_batch\n",
    "        print(f\"\\nLast Batch (Batch {total_batches}):\")\n",
    "        print(f\"Batch size (X): {X.shape[0]}\")\n",
    "        print(f\"X shape: {X.shape}\")\n",
    "        print(f\"Y_seq shape: {Y_seq.shape}\")\n",
    "        print(f\"Y_target shape: {Y_target.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T00:58:33.375709Z",
     "start_time": "2024-08-17T00:58:33.371109Z"
    }
   },
   "id": "f54b4851944d925",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Batches: 45\n",
      "First Batch (Batch 1):\n",
      "Batch size (X): 32\n",
      "X shape: torch.Size([32, 1, 5, 400, 400])\n",
      "Y_seq shape: torch.Size([32, 20, 1])\n",
      "Y_target shape: torch.Size([32, 1])\n",
      "\n",
      "Last Batch (Batch 45):\n",
      "Batch size (X): 12\n",
      "X shape: torch.Size([12, 1, 5, 400, 400])\n",
      "Y_seq shape: torch.Size([12, 20, 1])\n",
      "Y_target shape: torch.Size([12, 1])\n"
     ]
    }
   ],
   "source": [
    "inspect_first_and_last_batch(train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T00:58:34.274836Z",
     "start_time": "2024-08-17T00:58:33.376240Z"
    }
   },
   "id": "de3b4192bd924e0f",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Batches: 12\n",
      "First Batch (Batch 1):\n",
      "Batch size (X): 32\n",
      "X shape: torch.Size([32, 1, 5, 400, 400])\n",
      "Y_seq shape: torch.Size([32, 20, 1])\n",
      "Y_target shape: torch.Size([32, 1])\n",
      "\n",
      "Last Batch (Batch 12):\n",
      "Batch size (X): 3\n",
      "X shape: torch.Size([3, 1, 5, 400, 400])\n",
      "Y_seq shape: torch.Size([3, 20, 1])\n",
      "Y_target shape: torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "inspect_first_and_last_batch(val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T00:58:34.482562Z",
     "start_time": "2024-08-17T00:58:34.275977Z"
    }
   },
   "id": "9b4e2418bec4a98e",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = tuple(k // 2 for k in kernel_size)  # 对每个维度分别计算 padding\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers, batch_first=False, bias=True):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        print(f'start ConvLSTM forward pass...')\n",
    "        if not self.batch_first:\n",
    "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        b, _, _, h, w = input_tensor.size()\n",
    "        if hidden_state is None:\n",
    "            hidden_state = self._init_hidden(batch_size=b, image_size=(h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :], cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "                print(f'Layer {layer_idx+1}/{self.num_layers}, Step {t+1}/{seq_len} - Hidden state shape: {h.shape}')\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "            \n",
    "        print(f'ConvLSTM forward pass completed.')\n",
    "\n",
    "        return layer_output_list, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or isinstance(kernel_size, list)):\n",
    "            raise ValueError('`kernel_size` must be a tuple or list')\n",
    "        if isinstance(kernel_size, list) and len(kernel_size) != len(kernel_size):\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "class ConvLSTMModel(nn.Module):\n",
    "    def __init__(self, seq_length, input_dim, hidden_dim, kernel_size, num_layers):\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "        self.conv_lstm = ConvLSTM(input_dim=input_dim, hidden_dim=hidden_dim, kernel_size=kernel_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim[-1] * 400 * 400, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f'start ConvLSTMModel forward pass...')\n",
    "        b, t, c, h, w = x.size()\n",
    "        print(f'Input shape: {x.shape}')\n",
    "        \n",
    "        conv_lstm_out, _ = self.conv_lstm(x)\n",
    "        print(f'conv_lstm_out[-1].shape: {conv_lstm_out[-1].shape}')\n",
    "        print(f'conv_lstm_out[-1][:, -1, :, :, :]: {conv_lstm_out[-1][:, -1, :, :, :].shape}')\n",
    "        last_time_step = conv_lstm_out[-1][:, -1, :, :, :]\n",
    "        \n",
    "        print(f'Last time step shape: {last_time_step.shape}')\n",
    "        \n",
    "        last_time_step = last_time_step.view(last_time_step.size(0), -1)  # flatten\n",
    "        output = self.fc(last_time_step)\n",
    "        print(f'Output shape: {output.shape}')\n",
    "        print(f'ConvLSTMModel forward pass completed.')\n",
    "        return output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T00:58:34.493938Z",
     "start_time": "2024-08-17T00:58:34.482562Z"
    }
   },
   "id": "a5f30d5dbbe401b4",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 逐步训练模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2172484ea431d803"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 初始化并训练模型\n",
    "conv_lstm_model = ConvLSTMModel(seq_length=seq_length, input_dim=5, hidden_dim=[64, 128], kernel_size=[(3, 3), (3, 3)], num_layers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T00:58:36.524447Z",
     "start_time": "2024-08-17T00:58:36.461381Z"
    }
   },
   "id": "f82b1abde3cb1522",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = conv_lstm_model\n",
    "train_loader = train_loader\n",
    "val_loader = val_loader\n",
    "num_epochs = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T00:58:37.047846Z",
     "start_time": "2024-08-17T00:58:37.044781Z"
    }
   },
   "id": "86d5dbea3daf762b",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T00:58:38.219623Z",
     "start_time": "2024-08-17T00:58:37.536078Z"
    }
   },
   "id": "976858ba5b37ac43",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "epoch = 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T00:58:39.817234Z",
     "start_time": "2024-08-17T00:58:39.814235Z"
    }
   },
   "id": "42b6c1898af49c6b",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Training...\n",
      "start training batch 1/45, X shape: torch.Size([32, 1, 5, 400, 400]), Y shape: torch.Size([32, 1])\n",
      "Input shape: torch.Size([32, 1, 5, 400, 400])\n",
      "Layer 1/2, Step 1/1 - Hidden state shape: torch.Size([32, 64, 400, 400])\n",
      "Layer 2/2, Step 1/1 - Hidden state shape: torch.Size([32, 128, 400, 400])\n",
      "Last time step shape: torch.Size([32, 128, 400, 400])\n",
      "Output shape: torch.Size([32, 1])\n",
      "start calculating loss...\n",
      "start backpropagation...\n"
     ]
    }
   ],
   "source": [
    "print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "model.train()\n",
    "print('Training...')\n",
    "train_loss = 0.0\n",
    "for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "    X, _, Y = batch\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f'start training batch {batch_idx+1}/{len(train_loader)}, X shape: {X.shape}, Y shape: {Y.shape}')\n",
    "    output = model(X)\n",
    "\n",
    "    print(f'start calculating loss...')\n",
    "    loss = criterion(output, Y)\n",
    "\n",
    "    print(f'start backpropagation...')\n",
    "    loss.backward()\n",
    "\n",
    "    print(f'start updating weights...')\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T00:58:40.632528Z"
    }
   },
   "id": "3aacfff3d81faa76"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "val_loss = 0.0\n",
    "model.eval()\n",
    "print('Validating...')\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(val_loader):\n",
    "        X, _, Y = batch\n",
    "        print(f'start validating batch {batch_idx+1}/{len(val_loader)}, X shape: {X.shape}, Y shape: {Y.shape}')\n",
    "        output = model(X)\n",
    "\n",
    "        print(f'start calculating loss...')\n",
    "        loss = criterion(output, Y)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf81105cf61029ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    model.train()\n",
    "    print('Training...')\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "        X, _, Y = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(f'start training batch {batch_idx+1}/{len(train_loader)}, X shape: {X.shape}, Y shape: {Y.shape}')\n",
    "        output = model(X)\n",
    "\n",
    "        print(f'start calculating loss...')\n",
    "        loss = criterion(output, Y)\n",
    "\n",
    "        print(f'start backpropagation...')\n",
    "        loss.backward()\n",
    "\n",
    "        print(f'start updating weights...')\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    print('Validating...')\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            X, _, Y = batch\n",
    "            print(f'start validating batch {batch_idx+1}/{len(val_loader)}, X shape: {X.shape}, Y shape: {Y.shape}')\n",
    "            output = model(X)\n",
    "\n",
    "            print(f'start calculating loss...')\n",
    "            loss = criterion(output, Y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "342163967da35fb8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    print('Start training...')\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        model.train()\n",
    "        print('Training...')\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            \n",
    "            X, _, Y = batch\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            print(f'start training batch {batch_idx+1}/{len(train_loader)}, X shape: {X.shape}, Y shape: {Y.shape}')\n",
    "            output = model(X)\n",
    "            \n",
    "            print(f'start calculating loss...')\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            print(f'start backpropagation...')\n",
    "            loss.backward()\n",
    "            \n",
    "            print(f'start updating weights...')\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        print('Validating...')\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                X, _, Y = batch\n",
    "                print(f'start validating batch {batch_idx+1}/{len(val_loader)}, X shape: {X.shape}, Y shape: {Y.shape}')\n",
    "                output = model(X)\n",
    "                \n",
    "                print(f'start calculating loss...')\n",
    "                loss = criterion(output, Y)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T00:54:17.221397Z",
     "start_time": "2024-08-17T00:54:17.213512Z"
    }
   },
   "id": "16b3ad7755eded99",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 初始化并训练模型\n",
    "conv_lstm_model = ConvLSTMModel(seq_length=seq_length, input_dim=5, hidden_dim=[64, 128], kernel_size=[(3, 3), (3, 3)], num_layers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T00:54:17.279868Z",
     "start_time": "2024-08-17T00:54:17.222406Z"
    }
   },
   "id": "2998b80594e12b34",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch 1/2\n",
      "Training...\n",
      "start training batch 1/45, X shape: torch.Size([32, 1, 5, 400, 400]), Y shape: torch.Size([32, 1])\n",
      "Input shape: torch.Size([32, 1, 5, 400, 400])\n",
      "Layer 1/2, Step 1/1 - Hidden state shape: torch.Size([32, 64, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "train_model(conv_lstm_model, train_loader, val_loader, num_epochs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T00:54:17.280872Z"
    }
   },
   "id": "f4305ed62d5f56b4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e7573f39fac46d03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
