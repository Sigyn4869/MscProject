{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 3D-CNN Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "891711670cebda49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:53:38.144330Z",
     "start_time": "2024-08-17T19:53:37.995596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "BH_tif_400_400_after_processing = pd.read_csv('useful_data_after_processing/BH_tif_400_400_after_processing.csv',\n",
    "                                              sep=',', header=None)\n",
    "BV_tif_400_400_after_processing = pd.read_csv('useful_data_after_processing/BV_tif_400_400_after_processing.csv',\n",
    "                                              sep=',', header=None)\n",
    "CNM_tif_400_400_after_processing = pd.read_csv('useful_data_after_processing/CNM_tif_400_400_after_processing.csv',\n",
    "                                               sep=',', header=None)\n",
    "LAI_tif_400_400_after_processing = pd.read_csv('useful_data_after_processing/LAI_tif_400_400_after_processing.csv',\n",
    "                                               sep=',', header=None)\n",
    "DSM_tif_400_400_after_processing = pd.read_csv('useful_data_after_processing/DSM_tif_400_400_after_processing.csv',\n",
    "                                               sep=',', header=None)\n",
    "Weather_1795_6_after_processing = pd.read_csv('useful_data_after_processing/weather_1795_6.csv', sep=',')\n"
   ],
   "id": "df41423e8f80eeb3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:53:38.363728Z",
     "start_time": "2024-08-17T19:53:38.357756Z"
    }
   },
   "cell_type": "code",
   "source": "Weather_1795_6_after_processing.shape",
   "id": "c2ae735df5349849",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:53:38.964358Z",
     "start_time": "2024-08-17T19:53:38.960625Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "cffb9668f26b913d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:53:39.738664Z",
     "start_time": "2024-08-17T19:53:39.730640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = np.stack([BH_tif_400_400_after_processing, BV_tif_400_400_after_processing, CNM_tif_400_400_after_processing,\n",
    "              LAI_tif_400_400_after_processing, DSM_tif_400_400_after_processing], axis=-1)"
   ],
   "id": "3a1f5cbcadba1af3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:53:40.319719Z",
     "start_time": "2024-08-17T19:53:40.313666Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "id": "b5f8cff3410f577a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:53:40.569471Z",
     "start_time": "2024-08-17T19:53:40.565534Z"
    }
   },
   "cell_type": "code",
   "source": "Y = Weather_1795_6_after_processing['tempMax']",
   "id": "d35a4edccfa1f88e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:53:40.942609Z",
     "start_time": "2024-08-17T19:53:40.937379Z"
    }
   },
   "cell_type": "code",
   "source": "Y.shape",
   "id": "ee39a419b6bca87e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:53:41.771095Z",
     "start_time": "2024-08-17T19:53:41.764468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_loaded = X\n",
    "Y_loaded = Y\n",
    "X_loaded.shape, Y_loaded.shape"
   ],
   "id": "aefeace33d223776",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 400, 5), (1795,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:49:34.745642Z",
     "start_time": "2024-08-17T19:49:31.687338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "X_original = X_loaded  # X_original 是形状为 [400, 400, 5] 的空间数据\n",
    "Y_original = Y_loaded  # Y_original 是形状为 [1795,] 的温度时间序列数据\n",
    "seq_length = 20  # 设定时间序列的长度\n"
   ],
   "id": "86c9ff19e1ab4f01",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:49:35.477574Z",
     "start_time": "2024-08-17T19:49:35.472315Z"
    }
   },
   "cell_type": "code",
   "source": "X_original.shape, Y_original.shape",
   "id": "781cbc92e3df31ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 400, 5), (1795,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:49:36.509178Z",
     "start_time": "2024-08-17T19:49:36.504689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# \n",
    "# class TemporalSpatialDataset(Dataset):\n",
    "#     def __init__(self, X_spatial, Y_temporal, seq_length):\n",
    "#         self.X_spatial = X_spatial  # 空间数据，形状 [400, 400, 5]\n",
    "#         self.Y_temporal = Y_temporal  # 时间序列数据，形状 [1795,]\n",
    "#         self.seq_length = seq_length\n",
    "# \n",
    "#     def __len__(self):\n",
    "#         return len(self.Y_temporal) - self.seq_length\n",
    "# \n",
    "#     def __getitem__(self, idx):\n",
    "#         # 获取当前时间步的输入序列\n",
    "#         Y_seq = self.Y_temporal[idx:idx + self.seq_length]\n",
    "#         Y_target = self.Y_temporal[idx + self.seq_length]\n",
    "# \n",
    "#         # 转换为 PyTorch 张量\n",
    "#         Y_seq = torch.tensor(Y_seq, dtype=torch.float32).unsqueeze(-1)  # 形状 [seq_length, 1]\n",
    "#         Y_target = torch.tensor(Y_target, dtype=torch.float32).unsqueeze(-1)  # 形状 [1]\n",
    "# \n",
    "#         # 动态生成 X_spatial 输入，重复 seq_length 次\n",
    "#         X_spatial = torch.tensor(self.X_spatial, dtype=torch.float32).permute(2, 0, 1)  # 形状 [5, 400, 400]\n",
    "#         X_spatial = X_spatial.unsqueeze(0).repeat(self.seq_length, 1, 1, 1)  # 形状 [seq_length, 5, 400, 400]\n",
    "# \n",
    "#         return X_spatial, Y_seq, Y_target\n"
   ],
   "id": "53aa1d26ea210b1d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:49:37.197692Z",
     "start_time": "2024-08-17T19:49:37.189995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TemporalSpatialDataset:\n",
    "    def __init__(self, X_spatial, Y_temporal, seq_length):\n",
    "        self.X_spatial = X_spatial\n",
    "        self.Y_temporal = Y_temporal\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y_temporal) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 获取当前时间步的时间序列部分\n",
    "        Y_seq = self.Y_temporal[idx: idx + self.seq_length]\n",
    "        Y_target = self.Y_temporal[idx + self.seq_length]\n",
    "\n",
    "        # 将时间序列数据转换为 PyTorch 张量\n",
    "        Y_seq = torch.tensor(np.array(Y_seq), dtype=torch.float32).unsqueeze(-1)  # 形状 [seq_length, 1]\n",
    "        Y_target = torch.tensor(np.array(Y_target), dtype=torch.float32).unsqueeze(-1)  # 形状 [1]\n",
    "\n",
    "        # 动态生成 X_spatial 输入，X_spatial 的形状应该是 [5, 400, 400]\n",
    "        X_spatial = torch.tensor(np.array(self.X_spatial), dtype=torch.float32).permute(2, 0, 1)  # 形状 [5, 400, 400]\n",
    "\n",
    "        # 重复空间数据 seq_length 次，形成 [5, seq_length, 400, 400]\n",
    "        X_spatial = X_spatial.unsqueeze(1).repeat(1, self.seq_length, 1, 1)  # 形状 [5, 20, 400, 400]\n",
    "        X_spatial = X_spatial.permute(0, 2, 3, 1)  # 形状调整为 [5, 400, 400, 20]\n",
    "        X_spatial = X_spatial.unsqueeze(0)  # 添加 batch 维度，形状 [1, 5, 400, 400, 20]\n",
    "        X_spatial = X_spatial.permute(0, 1, 4, 2, 3)  # 调整维度为 [1, 5, 20, 400, 400]\n",
    "\n",
    "        return X_spatial.squeeze(0), Y_seq, Y_target\n"
   ],
   "id": "9e91bd63a4bd53c5",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:49:37.792575Z",
     "start_time": "2024-08-17T19:49:37.784209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = TemporalSpatialDataset(X_original, Y_original, seq_length)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ],
   "id": "7cacdd62a7791818",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:49:38.340744Z",
     "start_time": "2024-08-17T19:49:38.331467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN3DModel(nn.Module):\n",
    "    def __init__(self, input_channels, seq_length):\n",
    "        super(CNN3DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=input_channels, out_channels=32, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv3 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool = nn.MaxPool3d(kernel_size=(2, 2, 2))\n",
    "        self.fc1 = nn.Linear(128 * (seq_length // 2 // 2 // 2) * (400 // 2 // 2 // 2) * (400 // 2 // 2 // 2), 128)\n",
    "        self.fc2 = nn.Linear(128, 1)  # 预测一个标量，作为 Y_target 的预测\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f'Start CNN3DModel training, shape of x: {x.shape}')\n",
    "        \n",
    "        print(f'Start training layer 1')\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 第一层卷积 + 池化\n",
    "        \n",
    "        print(f'Start training layer 2')\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 第二层卷积 + 池化\n",
    "        \n",
    "        print(f'Start training layer 3')\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # 第三层卷积 + 池化\n",
    "        \n",
    "        print(f'Start flatten')\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ],
   "id": "be9a98f4c34e4dd8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:49:40.857697Z",
     "start_time": "2024-08-17T19:49:39.110388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 初始化模型\n",
    "model = CNN3DModel(input_channels=5, seq_length=seq_length)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n"
   ],
   "id": "fd9ffba308b37c67",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-17T19:49:40.872247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练循环\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (X_spatial, Y_seq, Y_target) in enumerate(train_loader):\n",
    "        print(f'Batch {batch_idx+1}/{len(train_loader)} in epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # 确保 X_spatial 的形状正确\n",
    "        print(f\"X_spatial.shape: {X_spatial.shape}\")\n",
    "        print(f\"Y_seq.shape: {Y_seq.shape}\")\n",
    "        print(f\"Y_target.shape: {Y_target.shape}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print(f'Start training')\n",
    "        output = model(X_spatial)\n",
    "        \n",
    "        print(f'Start calculating loss')\n",
    "        loss = criterion(output, Y_target)\n",
    "        \n",
    "        print(f'Start calculating gradients')\n",
    "        loss.backward()\n",
    "        \n",
    "        print(f'Start updating parameters')\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch_idx % 10 == 0:  # 每10个批次输出一次损失\n",
    "        #     print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx +1 }/len(train_loader), Loss: {loss.item():.4f}')\n",
    "        \n",
    "        print(loss.item())"
   ],
   "id": "e0c7744c2cba0b06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/45 in epoch 1/1\n",
      "X_spatial.shape: torch.Size([32, 5, 20, 400, 400])\n",
      "Y_seq.shape: torch.Size([32, 20, 1])\n",
      "Y_target.shape: torch.Size([32, 1])\n",
      "Start training\n",
      "Start CNN3DModel training, shape of x: torch.Size([32, 5, 20, 400, 400])\n",
      "Start training layer 1\n",
      "Start training layer 2\n",
      "Start training layer 3\n",
      "Start flatten\n",
      "Start calculating loss\n",
      "Start calculating gradients\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "313cd4f4746e8017"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3D-CNN Model GPU",
   "id": "ed6b75d7b3f7b9ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:53:46.554486Z",
     "start_time": "2024-08-17T19:53:46.548939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_loaded = X\n",
    "Y_loaded = Y\n",
    "X_loaded.shape, Y_loaded.shape"
   ],
   "id": "d42d62953bf08e60",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 400, 5), (1795,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:53:50.554514Z",
     "start_time": "2024-08-17T19:53:47.360464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "X_original = X_loaded  # X_original 是形状为 [400, 400, 5] 的空间数据\n",
    "Y_original = Y_loaded  # Y_original 是形状为 [1795,] 的温度时间序列数据\n",
    "seq_length = 20  # 设定时间序列的长度"
   ],
   "id": "cf7283e7d7c975ee",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:55:07.263927Z",
     "start_time": "2024-08-17T19:55:07.252704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 检查GPU是否可用并选择设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定义数据集类\n",
    "class TemporalSpatialDataset(Dataset):\n",
    "    def __init__(self, X_spatial, Y_temporal, seq_length):\n",
    "        self.X_spatial = X_spatial\n",
    "        self.Y_temporal = Y_temporal\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y_temporal) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        Y_seq = self.Y_temporal[idx: idx + self.seq_length]\n",
    "        Y_target = self.Y_temporal[idx + self.seq_length]\n",
    "\n",
    "        Y_seq = torch.tensor(np.array(Y_seq), dtype=torch.float32).unsqueeze(-1)  # 形状 [seq_length, 1]\n",
    "        Y_target = torch.tensor(np.array(Y_target), dtype=torch.float32).unsqueeze(-1)  # 形状 [1]\n",
    "\n",
    "        X_spatial = torch.tensor(np.array(self.X_spatial), dtype=torch.float32).permute(2, 0, 1)  # 形状 [5, 400, 400]\n",
    "        X_spatial = X_spatial.unsqueeze(1).repeat(1, self.seq_length, 1, 1)  # 形状 [5, 20, 400, 400]\n",
    "        X_spatial = X_spatial.permute(0, 2, 3, 1)  # 形状调整为 [5, 400, 400, 20]\n",
    "        X_spatial = X_spatial.unsqueeze(0)  # 添加 batch 维度，形状 [1, 5, 400, 400, 20]\n",
    "        X_spatial = X_spatial.permute(0, 1, 4, 2, 3)  # 调整维度为 [1, 5, 20, 400, 400]\n",
    "\n",
    "        return X_spatial.squeeze(0), Y_seq, Y_target\n",
    "\n",
    "# 初始化数据集和数据加载器\n",
    "dataset = TemporalSpatialDataset(X_original, Y_original, seq_length)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  # 批大小调整为64\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "# 定义模型\n",
    "class CNN3DModel(nn.Module):\n",
    "    def __init__(self, input_channels, seq_length):\n",
    "        super(CNN3DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=input_channels, out_channels=32, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv2 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv3 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool = nn.MaxPool3d(kernel_size=(2, 2, 2))\n",
    "        self.fc1 = nn.Linear(128 * (seq_length // 2 // 2 // 2) * (400 // 2 // 2 // 2) * (400 // 2 // 2 // 2), 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "964a704e1f210070",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:55:08.565892Z",
     "start_time": "2024-08-17T19:55:08.019278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 将模型加载到指定设备上\n",
    "model = CNN3DModel(input_channels=5, seq_length=seq_length).to(device)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)  # 学习率加倍\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 使用自动混合精度训练\n",
    "scaler = torch.amp.GradScaler() if device.type == 'cuda' else None\n",
    "\n"
   ],
   "id": "5a9703847d284b1d",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:02:56.920805Z",
     "start_time": "2024-08-17T19:59:08.882136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练循环\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_idx, (X_spatial, Y_seq, Y_target) in enumerate(train_loader):\n",
    "        X_spatial, Y_target = X_spatial.to(device), Y_target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):  # AMP 训练开启\n",
    "            output = model(X_spatial)\n",
    "            loss = criterion(output, Y_target)\n",
    "\n",
    "        scaler.scale(loss).backward()  # AMP 梯度缩放\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        print(f'EPOCH {epoch + 1} / {num_epochs} - Batch {batch_idx + 1} / {len(train_loader)} - Loss: {loss.item()}')\n",
    "\n",
    "        # if batch_idx % 10 == 0:\n",
    "        #     print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    print(f'Training Loss: {train_loss / len(train_loader)}')\n",
    "        "
   ],
   "id": "b42af4ad5b972",
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 32.29 GiB is allocated by PyTorch, and 5.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m     output \u001B[38;5;241m=\u001B[39m model(X_spatial)\n\u001B[0;32m     13\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(output, Y_target)\n\u001B[1;32m---> 15\u001B[0m scaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward()  \u001B[38;5;66;03m# AMP 梯度缩放\u001B[39;00m\n\u001B[0;32m     16\u001B[0m scaler\u001B[38;5;241m.\u001B[39mstep(optimizer)\n\u001B[0;32m     17\u001B[0m scaler\u001B[38;5;241m.\u001B[39mupdate()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:521\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    513\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    514\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    519\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    520\u001B[0m     )\n\u001B[1;32m--> 521\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    522\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    523\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:289\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    284\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    286\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 289\u001B[0m _engine_run_backward(\n\u001B[0;32m    290\u001B[0m     tensors,\n\u001B[0;32m    291\u001B[0m     grad_tensors_,\n\u001B[0;32m    292\u001B[0m     retain_graph,\n\u001B[0;32m    293\u001B[0m     create_graph,\n\u001B[0;32m    294\u001B[0m     inputs,\n\u001B[0;32m    295\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    296\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    297\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\graph.py:768\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    766\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    767\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 768\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    769\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    770\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    771\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    772\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 32.29 GiB is allocated by PyTorch, and 5.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "43c305415aba1fc9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
