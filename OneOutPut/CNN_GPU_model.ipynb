{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 数据读取"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "172535ad74d9e7c5"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "BH_tif_400_400_after_processing = pd.read_csv('../useful_data_after_processing/BH_tif_400_400_after_processing.csv',\n",
    "                                              sep=',', header=None)\n",
    "BV_tif_400_400_after_processing = pd.read_csv('../useful_data_after_processing/BV_tif_400_400_after_processing.csv',\n",
    "                                              sep=',', header=None)\n",
    "CNM_tif_400_400_after_processing = pd.read_csv('../useful_data_after_processing/CNM_tif_400_400_after_processing.csv',\n",
    "                                               sep=',', header=None)\n",
    "LAI_tif_400_400_after_processing = pd.read_csv('../useful_data_after_processing/LAI_tif_400_400_after_processing.csv',\n",
    "                                               sep=',', header=None)\n",
    "DSM_tif_400_400_after_processing = pd.read_csv('../useful_data_after_processing/DSM_tif_400_400_after_processing.csv',\n",
    "                                               sep=',', header=None)\n",
    "Weather_1795_6_after_processing = pd.read_csv('../useful_data_after_processing/weather_1795_6.csv', sep=',')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T19:47:44.771646Z",
     "start_time": "2024-08-17T19:47:44.640983Z"
    }
   },
   "id": "4f8001ec380311d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:47:45.460013Z",
     "start_time": "2024-08-17T19:47:45.449459Z"
    }
   },
   "cell_type": "code",
   "source": "Weather_1795_6_after_processing",
   "id": "6e51c2baa3acf8a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      tempMin  tempMax  cloudCover  humidity  windSpeed  visibility\n",
       "0        7.53    12.23        0.80      0.89      14.69        4.43\n",
       "1        3.58     7.15        0.62      0.79      15.04        5.64\n",
       "2       -0.61     6.54        0.31      0.84       4.48        6.20\n",
       "3       -0.63     7.59        0.78      0.85       4.35        6.22\n",
       "4        6.51    10.43        0.85      0.91       6.20        5.91\n",
       "...       ...      ...         ...       ...        ...         ...\n",
       "1790     8.55    10.57        0.96      0.85       6.80       10.00\n",
       "1791     5.79     9.40        0.87      0.85       6.82        9.03\n",
       "1792     2.30     6.67        0.40      0.79       5.15       10.00\n",
       "1793     1.08     6.14        0.18      0.76       4.85        9.11\n",
       "1794     0.42     5.69        0.55      0.72       4.79       10.00\n",
       "\n",
       "[1795 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempMin</th>\n",
       "      <th>tempMax</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>visibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.53</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.69</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.58</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.79</td>\n",
       "      <td>15.04</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.61</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4.48</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.63</td>\n",
       "      <td>7.59</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4.35</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.51</td>\n",
       "      <td>10.43</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>6.20</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>8.55</td>\n",
       "      <td>10.57</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>5.79</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.82</td>\n",
       "      <td>9.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>2.30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5.15</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>1.08</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.76</td>\n",
       "      <td>4.85</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.42</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4.79</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据处理"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b92466b03bef8597"
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T19:47:48.220347Z",
     "start_time": "2024-08-17T19:47:48.215947Z"
    }
   },
   "id": "fd2b51a1463d7e0b",
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "X = np.stack([BH_tif_400_400_after_processing, BV_tif_400_400_after_processing, CNM_tif_400_400_after_processing,\n",
    "              LAI_tif_400_400_after_processing, DSM_tif_400_400_after_processing], axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T19:47:48.998953Z",
     "start_time": "2024-08-17T19:47:48.992086Z"
    }
   },
   "id": "8c674fac3ae26795",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:05:17.862474Z",
     "start_time": "2024-08-17T19:05:17.858600Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "id": "ff03718762474e52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "Y = Weather_1795_6_after_processing['tempMax']",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T19:05:17.918175Z",
     "start_time": "2024-08-17T19:05:17.914443Z"
    }
   },
   "id": "cba4ce3bfed06c58",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "Y.shape",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T19:05:17.979842Z",
     "start_time": "2024-08-17T19:05:17.975755Z"
    }
   },
   "id": "ff62b6c1457a9df8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 模型构建"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "546fae4e986b1c00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:00:16.473574Z",
     "start_time": "2024-08-17T20:00:16.461914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_original = X\n",
    "Y_original = Y\n",
    "X_original.shape, Y_original.shape"
   ],
   "id": "3441766ee519ed4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 400, 5), (1795,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:00:57.722122Z",
     "start_time": "2024-08-17T20:00:57.715955Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "c187fd495036877e",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:13:38.994031Z",
     "start_time": "2024-08-17T20:13:38.849041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设置设备：GPU 如果可用，否则使用 CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "b8124fe18c9937a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:14:20.139245Z",
     "start_time": "2024-08-17T20:14:19.875935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 初始设定 n = 5\n",
    "n = 5\n",
    "seq_length = 20\n",
    "\n",
    "# 将时间序列拆分为输入序列和预测值\n",
    "def create_sequences(data, seq_length):\n",
    "    X_seq = []\n",
    "    Y_seq = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X_seq.append(data[i:i + seq_length])\n",
    "        Y_seq.append(data[i + seq_length])\n",
    "    return np.array(X_seq), np.array(Y_seq)\n",
    "\n",
    "\n",
    "# 拆分时间序列数据\n",
    "Y_seq, Y_target = create_sequences(Y_original, seq_length)\n",
    "Y_seq = np.expand_dims(Y_seq, axis=-1)  # [980, 20, 1]\n",
    "Y_target = np.expand_dims(Y_target, axis=-1)  # [980, 1]\n"
   ],
   "id": "5c25f52ded638e82",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:15:10.230810Z",
     "start_time": "2024-08-17T20:14:20.154744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 转换为 PyTorch 张量并移动到设备上\n",
    "X_land = torch.tensor(X_original, dtype=torch.float32).unsqueeze(0).repeat(Y_seq.shape[0], 1, 1, 1).to(device)\n",
    "Y_seq = torch.tensor(Y_seq, dtype=torch.float32).to(device)\n",
    "Y_target = torch.tensor(Y_target, dtype=torch.float32).to(device)"
   ],
   "id": "530a7a82815c7e00",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:15:10.498403Z",
     "start_time": "2024-08-17T20:15:10.484646Z"
    }
   },
   "cell_type": "code",
   "source": "X_land.shape, Y_seq.shape, Y_target.shape",
   "id": "24c77e1c222d2155",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1775, 400, 400, 5]),\n",
       " torch.Size([1775, 20, 1]),\n",
       " torch.Size([1775, 1]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:06.234326Z",
     "start_time": "2024-08-17T20:16:06.226849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "lr = 0.001 * batch_size / 32 * 2"
   ],
   "id": "82722d2f0da0483b",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:07.028137Z",
     "start_time": "2024-08-17T20:16:06.951966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# 数据集大小\n",
    "total_size = X_land.shape[0]\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "# 创建使用完整 X_land 的 DataLoader\n",
    "train_dataset_full, val_dataset_full = random_split(\n",
    "    TensorDataset(X_land.to(device), Y_seq.to(device), Y_target.to(device)),\n",
    "    [train_size, val_size]\n",
    ")\n",
    "\n",
    "train_loader_full = DataLoader(train_dataset_full, batch_size=batch_size, shuffle=True)\n",
    "val_loader_full = DataLoader(val_dataset_full, batch_size=batch_size)\n",
    "\n",
    "# 创建使用单独通道的 DataLoader\n",
    "channels = [0, 1, 2, 3, 4]\n",
    "train_loaders = {}\n",
    "val_loaders = {}\n",
    "\n",
    "for channel in channels:\n",
    "    X_land_channel = X_land[:, :, :, channel:channel + 1].to(device)  # 选择单个通道并移动到设备\n",
    "    train_dataset_channel, val_dataset_channel = random_split(\n",
    "        TensorDataset(X_land_channel, Y_seq.to(device), Y_target.to(device)),\n",
    "        [train_size, val_size]\n",
    "    )\n",
    "\n",
    "    train_loaders[channel] = DataLoader(train_dataset_channel, batch_size=batch_size, shuffle=True)\n",
    "    val_loaders[channel] = DataLoader(val_dataset_channel, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 结果展示\n",
    "print(\"train_loader_full length:\", len(train_loader_full))\n",
    "print(\"val_loader_full length:\", len(val_loader_full))\n",
    "\n",
    "for channel in channels:\n",
    "    print(f\"train_loader_channel_{channel} length:\", len(train_loaders[channel]))\n",
    "    print(f\"val_loader_channel_{channel} length:\", len(val_loaders[channel]))\n"
   ],
   "id": "8c4bc72bd3adfb09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader_full length: 12\n",
      "val_loader_full length: 3\n",
      "train_loader_channel_0 length: 12\n",
      "val_loader_channel_0 length: 3\n",
      "train_loader_channel_1 length: 12\n",
      "val_loader_channel_1 length: 3\n",
      "train_loader_channel_2 length: 12\n",
      "val_loader_channel_2 length: 3\n",
      "train_loader_channel_3 length: 12\n",
      "val_loader_channel_3 length: 3\n",
      "train_loader_channel_4 length: 12\n",
      "val_loader_channel_4 length: 3\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:07.951243Z",
     "start_time": "2024-08-17T20:16:07.941457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 输出dataloader的信息, 输出第一次和最后一次的信息\n",
    "def print_dataloader_info(loader):\n",
    "    for i, (land_data, temp_seq, target) in enumerate(loader):\n",
    "\n",
    "        if i == 0 or i == len(loader) - 1:\n",
    "            print(f'lenth of loader: {len(loader)}')\n",
    "            print(f'Batch {i + 1}')\n",
    "            print(f'Land Data Shape: {land_data.shape}')\n",
    "            print(f'Temporal Sequence Shape: {temp_seq.shape}')\n",
    "            print(f'Target Shape: {target.shape}')\n",
    "            print()"
   ],
   "id": "7d7e010063aa900e",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:15.970219Z",
     "start_time": "2024-08-17T20:16:14.609993Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_info(train_loader_full)",
   "id": "b4fd341baa5cb56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of loader: 12\n",
      "Batch 1\n",
      "Land Data Shape: torch.Size([128, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([128, 20, 1])\n",
      "Target Shape: torch.Size([128, 1])\n",
      "\n",
      "lenth of loader: 12\n",
      "Batch 12\n",
      "Land Data Shape: torch.Size([12, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([12, 20, 1])\n",
      "Target Shape: torch.Size([12, 1])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:19.322503Z",
     "start_time": "2024-08-17T20:16:19.309998Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_info(val_loader_full)",
   "id": "fe6a530877688cd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of loader: 3\n",
      "Batch 1\n",
      "Land Data Shape: torch.Size([128, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([128, 20, 1])\n",
      "Target Shape: torch.Size([128, 1])\n",
      "\n",
      "lenth of loader: 3\n",
      "Batch 3\n",
      "Land Data Shape: torch.Size([99, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([99, 20, 1])\n",
      "Target Shape: torch.Size([99, 1])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:20.856538Z",
     "start_time": "2024-08-17T20:16:20.825639Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_info(train_loaders[0])",
   "id": "1c25e72bed10b0a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of loader: 12\n",
      "Batch 1\n",
      "Land Data Shape: torch.Size([128, 400, 400, 1])\n",
      "Temporal Sequence Shape: torch.Size([128, 20, 1])\n",
      "Target Shape: torch.Size([128, 1])\n",
      "\n",
      "lenth of loader: 12\n",
      "Batch 12\n",
      "Land Data Shape: torch.Size([12, 400, 400, 1])\n",
      "Temporal Sequence Shape: torch.Size([12, 20, 1])\n",
      "Target Shape: torch.Size([12, 1])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:21.883247Z",
     "start_time": "2024-08-17T20:16:21.870687Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_info(val_loaders[0])",
   "id": "3055d0f3ea6e78fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of loader: 3\n",
      "Batch 1\n",
      "Land Data Shape: torch.Size([128, 400, 400, 1])\n",
      "Temporal Sequence Shape: torch.Size([128, 20, 1])\n",
      "Target Shape: torch.Size([128, 1])\n",
      "\n",
      "lenth of loader: 3\n",
      "Batch 3\n",
      "Land Data Shape: torch.Size([99, 400, 400, 1])\n",
      "Temporal Sequence Shape: torch.Size([99, 20, 1])\n",
      "Target Shape: torch.Size([99, 1])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:19:31.509049Z",
     "start_time": "2024-08-17T20:19:31.504019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 输出一个dataloader每批次的最值\n",
    "def print_dataloader_min_max(loader):\n",
    "    for i, (land_data, temp_seq, target) in enumerate(loader):\n",
    "        print(f'Batch {i + 1}')\n",
    "        print(f'Land Data Min: {land_data.min():.4f}, Max: {land_data.max():.4f}')\n",
    "        print(f'Temporal Sequence Min: {temp_seq.min():.4f}, Max: {temp_seq.max():.4f}')\n",
    "        print(f'Target Min: {target.min():.4f}, Max: {target.max():.4f}')\n",
    "        print()"
   ],
   "id": "ba54632d0b36e90f",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:19:43.777418Z",
     "start_time": "2024-08-17T20:19:32.194215Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_min_max(train_loader_full)",
   "id": "9faece4a6b8fa214",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 1.4300, Max: 26.6600\n",
      "\n",
      "Batch 2\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.2200\n",
      "Target Min: 0.0200, Max: 25.9900\n",
      "\n",
      "Batch 3\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: -0.7900, Max: 23.8700\n",
      "\n",
      "Batch 4\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.7300, Max: 26.5100\n",
      "\n",
      "Batch 5\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 0.1800, Max: 30.2200\n",
      "\n",
      "Batch 6\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.2200\n",
      "Target Min: 1.2200, Max: 24.6300\n",
      "\n",
      "Batch 7\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.0100, Max: 28.9900\n",
      "\n",
      "Batch 8\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.5100, Max: 24.4200\n",
      "\n",
      "Batch 9\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: 0.5300, Max: 30.3600\n",
      "Target Min: 3.4700, Max: 24.5000\n",
      "\n",
      "Batch 10\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.0800, Max: 28.8200\n",
      "\n",
      "Batch 11\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -0.7900, Max: 30.3600\n",
      "Target Min: -1.3900, Max: 30.3600\n",
      "\n",
      "Batch 12\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: 2.7900, Max: 22.7200\n",
      "Target Min: 4.8700, Max: 21.2900\n",
      "\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:19:52.256308Z",
     "start_time": "2024-08-17T20:19:49.196287Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_min_max(val_loader_full)",
   "id": "80d8a86118fe2f4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -0.7900, Max: 30.3600\n",
      "Target Min: 4.1500, Max: 24.8900\n",
      "\n",
      "Batch 2\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 0.5300, Max: 23.5700\n",
      "\n",
      "Batch 3\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 28.8200\n",
      "Target Min: 0.9800, Max: 25.6000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:19:58.766623Z",
     "start_time": "2024-08-17T20:19:57.503604Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_min_max(train_loaders[0])",
   "id": "9cd991ddc7ee5ced",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: 0.9800, Max: 30.3600\n",
      "Target Min: 2.5100, Max: 30.3600\n",
      "\n",
      "Batch 2\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 0.0200, Max: 26.0300\n",
      "\n",
      "Batch 3\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.0900, Max: 28.7800\n",
      "\n",
      "Batch 4\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 3.5900, Max: 26.6600\n",
      "\n",
      "Batch 5\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -0.7900, Max: 30.3600\n",
      "Target Min: -0.7900, Max: 23.8000\n",
      "\n",
      "Batch 6\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 0.1800, Max: 25.0300\n",
      "\n",
      "Batch 7\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 28.8200\n",
      "Target Min: -1.3900, Max: 30.2200\n",
      "\n",
      "Batch 8\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.0600, Max: 25.0900\n",
      "\n",
      "Batch 9\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 0.8100, Max: 26.7200\n",
      "\n",
      "Batch 10\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 1.8100, Max: 24.9000\n",
      "\n",
      "Batch 11\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.6700, Max: 24.4200\n",
      "\n",
      "Batch 12\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -0.7900, Max: 26.0300\n",
      "Target Min: 4.0400, Max: 19.5300\n",
      "\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:20:03.756230Z",
     "start_time": "2024-08-17T20:20:03.299707Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_min_max(val_loaders[0])",
   "id": "76d8687ddcec4b1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 0.9800, Max: 25.6600\n",
      "\n",
      "Batch 2\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.2200\n",
      "Target Min: 3.8000, Max: 28.9900\n",
      "\n",
      "Batch 3\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.2200\n",
      "Target Min: 0.5300, Max: 25.9900\n",
      "\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:22.967682Z",
     "start_time": "2024-08-17T20:16:22.960938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ],
   "id": "1c17d02ce9b7a8b8",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:23.841660Z",
     "start_time": "2024-08-17T20:16:23.809853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义CNN特征提取器和LSTM模型\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(128 * 50 * 50, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.reshape(-1, 128 * 50 * 50)\n",
    "        x = torch.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class LSTMWithSpatialFeatures(nn.Module):\n",
    "    def __init__(self, seq_length, in_channels=1):\n",
    "        super(LSTMWithSpatialFeatures, self).__init__()  # 确保最开始调用 super().__init__()\n",
    "        # 判断是否使用CNN\n",
    "        if in_channels > 0:\n",
    "            self.use_cnn = True\n",
    "            self.cnn = CNNFeatureExtractor(in_channels=in_channels)\n",
    "            lstm_input_size = 128 + 1  # CNN输出的128维特征 + 1维时间序列数据\n",
    "        else:\n",
    "            self.use_cnn = False\n",
    "            lstm_input_size = 1  # 只有时间序列数据，没有CNN输出\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_size, hidden_size=128, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, land_data, temp_seq):\n",
    "        if self.use_cnn:\n",
    "\n",
    "            # 调整输入形状为 [batch_size, in_channels, height, width]\n",
    "            land_data = land_data.permute(0, 3, 1,\n",
    "                                          2)  # 之前的形状 [batch_size, 400, 400, 4] -> 新形状 [batch_size, 4, 400, 400]\n",
    "\n",
    "            cnn_out = self.cnn(land_data)\n",
    "            # 经过 CNN 处理后\n",
    "            # land_data -> [batch_size, 4, 400, 400]\n",
    "            # CNN 的输出 cnn_out -> [batch_size, 128]  # 经过卷积和全连接层后，输出为 128 维的特征向量\n",
    "\n",
    "            cnn_out = cnn_out.unsqueeze(1).repeat(1, temp_seq.size(1), 1)\n",
    "            # 在第二个维度（时间步长维度）增加一个维度，然后沿着这个维度重复\n",
    "            # cnn_out -> [batch_size, 1, 128] -> [batch_size, seq_length, 128]  # 这里 seq_length = temp_seq.size(1)\n",
    "\n",
    "            combined_input = torch.cat((cnn_out, temp_seq), dim=2)\n",
    "            # 将 CNN 输出的特征向量和温度序列数据结合\n",
    "            # temp_seq -> [batch_size, seq_length, 1]\n",
    "            # combined_input -> [batch_size, seq_length, 128 + 1] -> [batch_size, seq_length, 129]\n",
    "        else:\n",
    "            combined_input = temp_seq\n",
    "            # combined_input -> [batch_size, seq_length, 1]  只有时间序列数据\n",
    "\n",
    "        lstm_out, _ = self.lstm(combined_input)\n",
    "        # 经过 LSTM 层处理\n",
    "        # combined_input -> [batch_size, seq_length, 129]\n",
    "        # lstm_out -> [batch_size, seq_length, 128]  # LSTM 的输出是 128 维的特征向量        \n",
    "\n",
    "        output = self.fc(lstm_out[:, -1, :])\n",
    "        # 取 LSTM 最后一层输出，并通过全连接层进行预测\n",
    "        # lstm_out[:, -1, :] -> [batch_size, 128]\n",
    "        # output -> [batch_size, 1]  # 最终输出一个标量，表示下一时间步长的预测值\n",
    "\n",
    "        return output\n"
   ],
   "id": "57ddfe5a08b6b11e",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:24.607123Z",
     "start_time": "2024-08-17T20:16:24.581429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练和验证函数\n",
    "def train_and_evaluate(model, train_loader, val_loader, num_epochs=10):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    val_losses = []\n",
    "\n",
    "    # 在CUDA上启用AMP（混合精度）\n",
    "    scaler = torch.amp.GradScaler() if device.type == 'cuda' else None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'----------Epoch {epoch + 1}/{num_epochs}----------')\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        print('----------Training----------')\n",
    "        for i, (land_data, temp_seq, target) in enumerate(train_loader):\n",
    "            land_data, temp_seq, target = land_data.to(device), temp_seq.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 使用新的 AMP API 的 autocast\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                output = model(land_data, temp_seq)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "            if scaler:\n",
    "                # 使用混合精度缩放梯度\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # 正常的反向传播\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # output = model(land_data, temp_seq)\n",
    "            # loss = criterion(output, target)\n",
    "            # \n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            print(f'EPOCH {epoch + 1} / {num_epochs} - Batch {i + 1} / {len(train_loader)} - Loss: {loss.item()}')\n",
    "        print(f'Training Loss: {train_loss / len(train_loader)}')\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        print('----------Validation----------')\n",
    "        with torch.no_grad():\n",
    "            for i, (land_data, temp_seq, target) in enumerate(val_loader):\n",
    "                land_data, temp_seq, target = land_data.to(device), temp_seq.to(device), target.to(device)\n",
    "\n",
    "                with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                    output = model(land_data, temp_seq)\n",
    "                    loss = criterion(output, target)\n",
    "                    \n",
    "                # output = model(land_data, temp_seq)\n",
    "                # loss = criterion(output, target)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                print(f'EPOCH {epoch + 1} / {num_epochs} - Batch {i + 1} / {len(val_loader)} - Loss: {loss.item()}')\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f'Validation Loss: {avg_val_loss}')\n",
    "\n",
    "    return val_losses"
   ],
   "id": "6feec6193c4703c0",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:27.440254Z",
     "start_time": "2024-08-17T20:16:27.435178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 比较不同模型的函数\n",
    "specific_indices = None"
   ],
   "id": "461dbae2c6312665",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:28.444375Z",
     "start_time": "2024-08-17T20:16:28.439155Z"
    }
   },
   "cell_type": "code",
   "source": "num_epochs = 10",
   "id": "336b3706aa43e271",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:29.158229Z",
     "start_time": "2024-08-17T20:16:29.153806Z"
    }
   },
   "cell_type": "code",
   "source": "results = {}",
   "id": "213a1b7bfb1dd794",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:16:29.864215Z",
     "start_time": "2024-08-17T20:16:29.843113Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_info(train_loader_full)",
   "id": "ab061903f394a03e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of loader: 12\n",
      "Batch 1\n",
      "Land Data Shape: torch.Size([128, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([128, 20, 1])\n",
      "Target Shape: torch.Size([128, 1])\n",
      "\n",
      "lenth of loader: 12\n",
      "Batch 12\n",
      "Land Data Shape: torch.Size([12, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([12, 20, 1])\n",
      "Target Shape: torch.Size([12, 1])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:17:36.063795Z",
     "start_time": "2024-08-17T20:16:34.585944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# Baseline\n",
    "print(\"Training baseline model...\")\n",
    "model_baseline = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=0).to(device)  # 无空间数据\n",
    "results[\"Baseline\"] = train_and_evaluate(model_baseline, train_loader_full, val_loader_full, num_epochs=num_epochs)\n",
    "print(f\"Baseline MSE: {results['Baseline']}\")"
   ],
   "id": "ab97d2562fca8ddc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline model...\n",
      "----------Epoch 1/10----------\n",
      "----------Training----------\n",
      "EPOCH 1 / 10 - Batch 1 / 12 - Loss: 212.59657287597656\n",
      "EPOCH 1 / 10 - Batch 2 / 12 - Loss: 191.2994384765625\n",
      "EPOCH 1 / 10 - Batch 3 / 12 - Loss: 207.00173950195312\n",
      "EPOCH 1 / 10 - Batch 4 / 12 - Loss: 207.4920196533203\n",
      "EPOCH 1 / 10 - Batch 5 / 12 - Loss: 201.72177124023438\n",
      "EPOCH 1 / 10 - Batch 6 / 12 - Loss: 207.32342529296875\n",
      "EPOCH 1 / 10 - Batch 7 / 12 - Loss: 205.5303955078125\n",
      "EPOCH 1 / 10 - Batch 8 / 12 - Loss: 178.95697021484375\n",
      "EPOCH 1 / 10 - Batch 9 / 12 - Loss: 142.8464813232422\n",
      "EPOCH 1 / 10 - Batch 10 / 12 - Loss: 117.27037811279297\n",
      "EPOCH 1 / 10 - Batch 11 / 12 - Loss: 104.78070831298828\n",
      "EPOCH 1 / 10 - Batch 12 / 12 - Loss: 103.28744506835938\n",
      "Training Loss: 173.34227879842123\n",
      "----------Validation----------\n",
      "EPOCH 1 / 10 - Batch 1 / 3 - Loss: 69.90702819824219\n",
      "EPOCH 1 / 10 - Batch 2 / 3 - Loss: 65.78007507324219\n",
      "EPOCH 1 / 10 - Batch 3 / 3 - Loss: 60.207035064697266\n",
      "Validation Loss: 65.29804611206055\n",
      "----------Epoch 2/10----------\n",
      "----------Training----------\n",
      "EPOCH 2 / 10 - Batch 1 / 12 - Loss: 80.2356185913086\n",
      "EPOCH 2 / 10 - Batch 2 / 12 - Loss: 52.60943603515625\n",
      "EPOCH 2 / 10 - Batch 3 / 12 - Loss: 38.053077697753906\n",
      "EPOCH 2 / 10 - Batch 4 / 12 - Loss: 43.906044006347656\n",
      "EPOCH 2 / 10 - Batch 5 / 12 - Loss: 39.15757369995117\n",
      "EPOCH 2 / 10 - Batch 6 / 12 - Loss: 34.3444709777832\n",
      "EPOCH 2 / 10 - Batch 7 / 12 - Loss: 29.31372833251953\n",
      "EPOCH 2 / 10 - Batch 8 / 12 - Loss: 32.53913879394531\n",
      "EPOCH 2 / 10 - Batch 9 / 12 - Loss: 29.382476806640625\n",
      "EPOCH 2 / 10 - Batch 10 / 12 - Loss: 27.85346221923828\n",
      "EPOCH 2 / 10 - Batch 11 / 12 - Loss: 31.44988250732422\n",
      "EPOCH 2 / 10 - Batch 12 / 12 - Loss: 16.206932067871094\n",
      "Training Loss: 37.920986811319985\n",
      "----------Validation----------\n",
      "EPOCH 2 / 10 - Batch 1 / 3 - Loss: 23.442325592041016\n",
      "EPOCH 2 / 10 - Batch 2 / 3 - Loss: 29.688865661621094\n",
      "EPOCH 2 / 10 - Batch 3 / 3 - Loss: 31.74287223815918\n",
      "Validation Loss: 28.291354497273762\n",
      "----------Epoch 3/10----------\n",
      "----------Training----------\n",
      "EPOCH 3 / 10 - Batch 1 / 12 - Loss: 26.204769134521484\n",
      "EPOCH 3 / 10 - Batch 2 / 12 - Loss: 33.5809440612793\n",
      "EPOCH 3 / 10 - Batch 3 / 12 - Loss: 26.225555419921875\n",
      "EPOCH 3 / 10 - Batch 4 / 12 - Loss: 29.048076629638672\n",
      "EPOCH 3 / 10 - Batch 5 / 12 - Loss: 33.41912841796875\n",
      "EPOCH 3 / 10 - Batch 6 / 12 - Loss: 33.31435012817383\n",
      "EPOCH 3 / 10 - Batch 7 / 12 - Loss: 24.467124938964844\n",
      "EPOCH 3 / 10 - Batch 8 / 12 - Loss: 33.36571502685547\n",
      "EPOCH 3 / 10 - Batch 9 / 12 - Loss: 29.70955467224121\n",
      "EPOCH 3 / 10 - Batch 10 / 12 - Loss: 34.309173583984375\n",
      "EPOCH 3 / 10 - Batch 11 / 12 - Loss: 35.1480827331543\n",
      "EPOCH 3 / 10 - Batch 12 / 12 - Loss: 34.37431335449219\n",
      "Training Loss: 31.097232341766357\n",
      "----------Validation----------\n",
      "EPOCH 3 / 10 - Batch 1 / 3 - Loss: 21.616628646850586\n",
      "EPOCH 3 / 10 - Batch 2 / 3 - Loss: 26.154321670532227\n",
      "EPOCH 3 / 10 - Batch 3 / 3 - Loss: 26.997913360595703\n",
      "Validation Loss: 24.922954559326172\n",
      "----------Epoch 4/10----------\n",
      "----------Training----------\n",
      "EPOCH 4 / 10 - Batch 1 / 12 - Loss: 31.819751739501953\n",
      "EPOCH 4 / 10 - Batch 2 / 12 - Loss: 29.756736755371094\n",
      "EPOCH 4 / 10 - Batch 3 / 12 - Loss: 27.807933807373047\n",
      "EPOCH 4 / 10 - Batch 4 / 12 - Loss: 22.475162506103516\n",
      "EPOCH 4 / 10 - Batch 5 / 12 - Loss: 31.52587127685547\n",
      "EPOCH 4 / 10 - Batch 6 / 12 - Loss: 19.52066421508789\n",
      "EPOCH 4 / 10 - Batch 7 / 12 - Loss: 26.969423294067383\n",
      "EPOCH 4 / 10 - Batch 8 / 12 - Loss: 30.159526824951172\n",
      "EPOCH 4 / 10 - Batch 9 / 12 - Loss: 29.162256240844727\n",
      "EPOCH 4 / 10 - Batch 10 / 12 - Loss: 34.93495178222656\n",
      "EPOCH 4 / 10 - Batch 11 / 12 - Loss: 25.087265014648438\n",
      "EPOCH 4 / 10 - Batch 12 / 12 - Loss: 27.05476188659668\n",
      "Training Loss: 28.022858778635662\n",
      "----------Validation----------\n",
      "EPOCH 4 / 10 - Batch 1 / 3 - Loss: 22.019527435302734\n",
      "EPOCH 4 / 10 - Batch 2 / 3 - Loss: 25.286083221435547\n",
      "EPOCH 4 / 10 - Batch 3 / 3 - Loss: 25.305278778076172\n",
      "Validation Loss: 24.203629811604817\n",
      "----------Epoch 5/10----------\n",
      "----------Training----------\n",
      "EPOCH 5 / 10 - Batch 1 / 12 - Loss: 28.717105865478516\n",
      "EPOCH 5 / 10 - Batch 2 / 12 - Loss: 28.991926193237305\n",
      "EPOCH 5 / 10 - Batch 3 / 12 - Loss: 29.32546043395996\n",
      "EPOCH 5 / 10 - Batch 4 / 12 - Loss: 27.345998764038086\n",
      "EPOCH 5 / 10 - Batch 5 / 12 - Loss: 25.010135650634766\n",
      "EPOCH 5 / 10 - Batch 6 / 12 - Loss: 31.506515502929688\n",
      "EPOCH 5 / 10 - Batch 7 / 12 - Loss: 22.72278594970703\n",
      "EPOCH 5 / 10 - Batch 8 / 12 - Loss: 27.80918312072754\n",
      "EPOCH 5 / 10 - Batch 9 / 12 - Loss: 20.94762420654297\n",
      "EPOCH 5 / 10 - Batch 10 / 12 - Loss: 26.72972297668457\n",
      "EPOCH 5 / 10 - Batch 11 / 12 - Loss: 26.061634063720703\n",
      "EPOCH 5 / 10 - Batch 12 / 12 - Loss: 25.852293014526367\n",
      "Training Loss: 26.751698811848957\n",
      "----------Validation----------\n",
      "EPOCH 5 / 10 - Batch 1 / 3 - Loss: 19.343101501464844\n",
      "EPOCH 5 / 10 - Batch 2 / 3 - Loss: 23.646434783935547\n",
      "EPOCH 5 / 10 - Batch 3 / 3 - Loss: 24.4807186126709\n",
      "Validation Loss: 22.490084966023762\n",
      "----------Epoch 6/10----------\n",
      "----------Training----------\n",
      "EPOCH 6 / 10 - Batch 1 / 12 - Loss: 21.972293853759766\n",
      "EPOCH 6 / 10 - Batch 2 / 12 - Loss: 24.658916473388672\n",
      "EPOCH 6 / 10 - Batch 3 / 12 - Loss: 21.558231353759766\n",
      "EPOCH 6 / 10 - Batch 4 / 12 - Loss: 22.85886001586914\n",
      "EPOCH 6 / 10 - Batch 5 / 12 - Loss: 24.22099494934082\n",
      "EPOCH 6 / 10 - Batch 6 / 12 - Loss: 24.748233795166016\n",
      "EPOCH 6 / 10 - Batch 7 / 12 - Loss: 24.902677536010742\n",
      "EPOCH 6 / 10 - Batch 8 / 12 - Loss: 29.15544891357422\n",
      "EPOCH 6 / 10 - Batch 9 / 12 - Loss: 26.496700286865234\n",
      "EPOCH 6 / 10 - Batch 10 / 12 - Loss: 25.413978576660156\n",
      "EPOCH 6 / 10 - Batch 11 / 12 - Loss: 19.944583892822266\n",
      "EPOCH 6 / 10 - Batch 12 / 12 - Loss: 25.124631881713867\n",
      "Training Loss: 24.254629294077557\n",
      "----------Validation----------\n",
      "EPOCH 6 / 10 - Batch 1 / 3 - Loss: 17.378936767578125\n",
      "EPOCH 6 / 10 - Batch 2 / 3 - Loss: 20.46573257446289\n",
      "EPOCH 6 / 10 - Batch 3 / 3 - Loss: 20.646196365356445\n",
      "Validation Loss: 19.496955235799152\n",
      "----------Epoch 7/10----------\n",
      "----------Training----------\n",
      "EPOCH 7 / 10 - Batch 1 / 12 - Loss: 26.870441436767578\n",
      "EPOCH 7 / 10 - Batch 2 / 12 - Loss: 21.70768165588379\n",
      "EPOCH 7 / 10 - Batch 3 / 12 - Loss: 23.48529815673828\n",
      "EPOCH 7 / 10 - Batch 4 / 12 - Loss: 20.6348876953125\n",
      "EPOCH 7 / 10 - Batch 5 / 12 - Loss: 21.279748916625977\n",
      "EPOCH 7 / 10 - Batch 6 / 12 - Loss: 19.82241439819336\n",
      "EPOCH 7 / 10 - Batch 7 / 12 - Loss: 20.507993698120117\n",
      "EPOCH 7 / 10 - Batch 8 / 12 - Loss: 20.75551414489746\n",
      "EPOCH 7 / 10 - Batch 9 / 12 - Loss: 14.98952865600586\n",
      "EPOCH 7 / 10 - Batch 10 / 12 - Loss: 24.09231948852539\n",
      "EPOCH 7 / 10 - Batch 11 / 12 - Loss: 15.146514892578125\n",
      "EPOCH 7 / 10 - Batch 12 / 12 - Loss: 18.111894607543945\n",
      "Training Loss: 20.617019812266033\n",
      "----------Validation----------\n",
      "EPOCH 7 / 10 - Batch 1 / 3 - Loss: 13.663629531860352\n",
      "EPOCH 7 / 10 - Batch 2 / 3 - Loss: 16.868831634521484\n",
      "EPOCH 7 / 10 - Batch 3 / 3 - Loss: 17.116748809814453\n",
      "Validation Loss: 15.88306999206543\n",
      "----------Epoch 8/10----------\n",
      "----------Training----------\n",
      "EPOCH 8 / 10 - Batch 1 / 12 - Loss: 22.362876892089844\n",
      "EPOCH 8 / 10 - Batch 2 / 12 - Loss: 21.37579345703125\n",
      "EPOCH 8 / 10 - Batch 3 / 12 - Loss: 17.2313232421875\n",
      "EPOCH 8 / 10 - Batch 4 / 12 - Loss: 20.16074562072754\n",
      "EPOCH 8 / 10 - Batch 5 / 12 - Loss: 14.167043685913086\n",
      "EPOCH 8 / 10 - Batch 6 / 12 - Loss: 18.234638214111328\n",
      "EPOCH 8 / 10 - Batch 7 / 12 - Loss: 18.22758674621582\n",
      "EPOCH 8 / 10 - Batch 8 / 12 - Loss: 19.776912689208984\n",
      "EPOCH 8 / 10 - Batch 9 / 12 - Loss: 15.053824424743652\n",
      "EPOCH 8 / 10 - Batch 10 / 12 - Loss: 13.852757453918457\n",
      "EPOCH 8 / 10 - Batch 11 / 12 - Loss: 13.850278854370117\n",
      "EPOCH 8 / 10 - Batch 12 / 12 - Loss: 16.755613327026367\n",
      "Training Loss: 17.587449550628662\n",
      "----------Validation----------\n",
      "EPOCH 8 / 10 - Batch 1 / 3 - Loss: 11.551858901977539\n",
      "EPOCH 8 / 10 - Batch 2 / 3 - Loss: 14.71590518951416\n",
      "EPOCH 8 / 10 - Batch 3 / 3 - Loss: 14.86494255065918\n",
      "Validation Loss: 13.710902214050293\n",
      "----------Epoch 9/10----------\n",
      "----------Training----------\n",
      "EPOCH 9 / 10 - Batch 1 / 12 - Loss: 12.25965690612793\n",
      "EPOCH 9 / 10 - Batch 2 / 12 - Loss: 13.097625732421875\n",
      "EPOCH 9 / 10 - Batch 3 / 12 - Loss: 18.829235076904297\n",
      "EPOCH 9 / 10 - Batch 4 / 12 - Loss: 15.21462631225586\n",
      "EPOCH 9 / 10 - Batch 5 / 12 - Loss: 19.383785247802734\n",
      "EPOCH 9 / 10 - Batch 6 / 12 - Loss: 16.703380584716797\n",
      "EPOCH 9 / 10 - Batch 7 / 12 - Loss: 12.564805030822754\n",
      "EPOCH 9 / 10 - Batch 8 / 12 - Loss: 14.355422973632812\n",
      "EPOCH 9 / 10 - Batch 9 / 12 - Loss: 14.37398910522461\n",
      "EPOCH 9 / 10 - Batch 10 / 12 - Loss: 15.285602569580078\n",
      "EPOCH 9 / 10 - Batch 11 / 12 - Loss: 12.346363067626953\n",
      "EPOCH 9 / 10 - Batch 12 / 12 - Loss: 16.786060333251953\n",
      "Training Loss: 15.100046078364054\n",
      "----------Validation----------\n",
      "EPOCH 9 / 10 - Batch 1 / 3 - Loss: 9.31279182434082\n",
      "EPOCH 9 / 10 - Batch 2 / 3 - Loss: 11.545708656311035\n",
      "EPOCH 9 / 10 - Batch 3 / 3 - Loss: 11.48222541809082\n",
      "Validation Loss: 10.780241966247559\n",
      "----------Epoch 10/10----------\n",
      "----------Training----------\n",
      "EPOCH 10 / 10 - Batch 1 / 12 - Loss: 12.538585662841797\n",
      "EPOCH 10 / 10 - Batch 2 / 12 - Loss: 14.794236183166504\n",
      "EPOCH 10 / 10 - Batch 3 / 12 - Loss: 14.832548141479492\n",
      "EPOCH 10 / 10 - Batch 4 / 12 - Loss: 11.44001579284668\n",
      "EPOCH 10 / 10 - Batch 5 / 12 - Loss: 12.88007926940918\n",
      "EPOCH 10 / 10 - Batch 6 / 12 - Loss: 13.038820266723633\n",
      "EPOCH 10 / 10 - Batch 7 / 12 - Loss: 10.906304359436035\n",
      "EPOCH 10 / 10 - Batch 8 / 12 - Loss: 10.162542343139648\n",
      "EPOCH 10 / 10 - Batch 9 / 12 - Loss: 11.708318710327148\n",
      "EPOCH 10 / 10 - Batch 10 / 12 - Loss: 13.729707717895508\n",
      "EPOCH 10 / 10 - Batch 11 / 12 - Loss: 14.599607467651367\n",
      "EPOCH 10 / 10 - Batch 12 / 12 - Loss: 5.141523361206055\n",
      "Training Loss: 12.147690773010254\n",
      "----------Validation----------\n",
      "EPOCH 10 / 10 - Batch 1 / 3 - Loss: 7.871373176574707\n",
      "EPOCH 10 / 10 - Batch 2 / 3 - Loss: 9.898035049438477\n",
      "EPOCH 10 / 10 - Batch 3 / 3 - Loss: 9.878708839416504\n",
      "Validation Loss: 9.216039021809896\n",
      "Baseline MSE: [65.29804611206055, 28.291354497273762, 24.922954559326172, 24.203629811604817, 22.490084966023762, 19.496955235799152, 15.88306999206543, 13.710902214050293, 10.780241966247559, 9.216039021809896]\n",
      "CPU times: total: 32.7 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:17:36.176281Z",
     "start_time": "2024-08-17T20:17:36.169256Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "789b23a2a046fcde",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baseline': [65.29804611206055,\n",
       "  28.291354497273762,\n",
       "  24.922954559326172,\n",
       "  24.203629811604817,\n",
       "  22.490084966023762,\n",
       "  19.496955235799152,\n",
       "  15.88306999206543,\n",
       "  13.710902214050293,\n",
       "  10.780241966247559,\n",
       "  9.216039021809896]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:17:36.373530Z",
     "start_time": "2024-08-17T20:17:36.371061Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ceefee697d5738a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# Baseline + n种所有空间数据\n",
    "print(f\"\\nTraining baseline + all {n} spatial features model...\")\n",
    "model_baseline_n = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=n).to(device)\n",
    "results[f\"Baseline + all {n} features\"] = train_and_evaluate(model_baseline_n, train_loader_full, val_loader_full,\n",
    "                                                             num_epochs=num_epochs)\n",
    "print(f\"Baseline + all {n} features MSE: {results[f'Baseline + all {n} features']}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T20:18:00.801458Z",
     "start_time": "2024-08-17T20:17:36.394307Z"
    }
   },
   "id": "c146335f0e32528",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training baseline + all 5 spatial features model...\n",
      "----------Epoch 1/10----------\n",
      "----------Training----------\n",
      "EPOCH 1 / 10 - Batch 1 / 12 - Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:4\u001B[0m\n",
      "Cell \u001B[1;32mIn[50], line 28\u001B[0m, in \u001B[0;36mtrain_and_evaluate\u001B[1;34m(model, train_loader, val_loader, num_epochs)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m scaler:\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;66;03m# 使用混合精度缩放梯度\u001B[39;00m\n\u001B[0;32m     27\u001B[0m     scaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 28\u001B[0m     scaler\u001B[38;5;241m.\u001B[39mstep(optimizer)\n\u001B[0;32m     29\u001B[0m     scaler\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;66;03m# 正常的反向传播\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\amp\\grad_scaler.py:454\u001B[0m, in \u001B[0;36mGradScaler.step\u001B[1;34m(self, optimizer, *args, **kwargs)\u001B[0m\n\u001B[0;32m    448\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munscale_(optimizer)\n\u001B[0;32m    450\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[0;32m    451\u001B[0m     \u001B[38;5;28mlen\u001B[39m(optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    452\u001B[0m ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo inf checks were recorded for this optimizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 454\u001B[0m retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_opt_step(optimizer, optimizer_state, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    456\u001B[0m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstage\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m OptState\u001B[38;5;241m.\u001B[39mSTEPPED\n\u001B[0;32m    458\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\amp\\grad_scaler.py:351\u001B[0m, in \u001B[0;36mGradScaler._maybe_opt_step\u001B[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_maybe_opt_step\u001B[39m(\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    345\u001B[0m     optimizer: torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mOptimizer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    349\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[0;32m    350\u001B[0m     retval: Optional[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 351\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28msum\u001B[39m(v\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[0;32m    352\u001B[0m         retval \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\amp\\grad_scaler.py:351\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_maybe_opt_step\u001B[39m(\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    345\u001B[0m     optimizer: torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mOptimizer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    349\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[0;32m    350\u001B[0m     retval: Optional[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 351\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28msum\u001B[39m(v\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[0;32m    352\u001B[0m         retval \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "2ad21d7828f57823",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Baseline + 单个空间数据",
   "id": "6706d2f445d04ee0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseline + BH 层\n",
    "model_baseline_BH = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=1).to(device)"
   ],
   "id": "d96e038ef46144a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "results[f\"Baseline + feature BH\"] = train_and_evaluate(model_baseline_BH, train_loaders[0], val_loaders[0],\n",
    "                                                       num_epochs=num_epochs)"
   ],
   "id": "4877ca206b6ffaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "313d856a378a74b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseline + BV 层\n",
    "model_baseline_BV = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=1).to(device)"
   ],
   "id": "5ba8911f640108ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "results[f\"Baseline + feature BV\"] = train_and_evaluate(model_baseline_BV, train_loaders[1], val_loaders[1],\n",
    "                                                       num_epochs=num_epochs)"
   ],
   "id": "f8db84cea3c1fec8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "ffaf116a62ca81ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseline + CNM 层\n",
    "model_baseline_CNM = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=1).to(device)"
   ],
   "id": "4bcc016cdbd837e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "results[f\"Baseline + feature CNM\"] = train_and_evaluate(model_baseline_CNM, train_loaders[2], val_loaders[2],\n",
    "                                                        num_epochs=num_epochs)"
   ],
   "id": "5b29e17e3f54dbf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "7c109e23e3de2792",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseline + LAI 层\n",
    "model_baseline_LAI = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=1).to(device)"
   ],
   "id": "ccf29648fa52aad4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "results[f\"Baseline + feature LAI\"] = train_and_evaluate(model_baseline_LAI, train_loaders[3], val_loaders[3],\n",
    "                                                        num_epochs=num_epochs)"
   ],
   "id": "8bbdcbeefe5e8bd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "112cb6ca09c28955",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseline + DSM 层\n",
    "model_baseline_DSM = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=1).to(device)"
   ],
   "id": "409a01f2f42f7257",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "results[f\"Baseline + feature DSM\"] = train_and_evaluate(model_baseline_DSM, train_loaders[4], val_loaders[4],\n",
    "                                                        num_epochs=num_epochs)"
   ],
   "id": "f15dfd94c8de60c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "results",
   "metadata": {
    "collapsed": false
   },
   "id": "691803927ea2d784",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 储存results\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('Results/RF_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "    "
   ],
   "id": "ea872b1259dfa804",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 模型名称\n",
    "model_names = list(results.keys())\n",
    "\n",
    "# 模型结果\n",
    "model_results = [results[model_name] for model_name in model_names]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "name_print = [\"Baseline\", \"B + 5 layers\", \"B + BH\", \"B + BV\", \"B + CNM\", \"B + LAI\", \"B + DEM\"]\n",
    "\n",
    "# 绘制条形图\n",
    "plt.bar(name_print, model_results, color='skyblue')\n",
    "\n",
    "# 倾斜45度显示模型名称\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 条形图上显示数值\n",
    "for i, result in enumerate(model_results):\n",
    "    plt.text(i, result + 0.01, f\"{result:.4f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Model Comparison')\n",
    "plt.show()\n"
   ],
   "id": "96f1219bf9dda8df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "445ac573c20d19cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
