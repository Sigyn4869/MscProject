{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 数据读取"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "172535ad74d9e7c5"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "BH_tif_400_400_after_processing = pd.read_csv('../useful_data_after_processing/BH_tif_400_400_after_processing.csv',\n",
    "                                              sep=',', header=None)\n",
    "BV_tif_400_400_after_processing = pd.read_csv('../useful_data_after_processing/BV_tif_400_400_after_processing.csv',\n",
    "                                              sep=',', header=None)\n",
    "CNM_tif_400_400_after_processing = pd.read_csv('../useful_data_after_processing/CNM_tif_400_400_after_processing.csv',\n",
    "                                               sep=',', header=None)\n",
    "LAI_tif_400_400_after_processing = pd.read_csv('../useful_data_after_processing/LAI_tif_400_400_after_processing.csv',\n",
    "                                               sep=',', header=None)\n",
    "DSM_tif_400_400_after_processing = pd.read_csv('../useful_data_after_processing/DSM_tif_400_400_after_processing.csv',\n",
    "                                               sep=',', header=None)\n",
    "Weather_1795_6_after_processing = pd.read_csv('../useful_data_after_processing/weather_1795_6.csv', sep=',')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T19:47:44.771646Z",
     "start_time": "2024-08-17T19:47:44.640983Z"
    }
   },
   "id": "4f8001ec380311d",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:47:45.460013Z",
     "start_time": "2024-08-17T19:47:45.449459Z"
    }
   },
   "cell_type": "code",
   "source": "Weather_1795_6_after_processing",
   "id": "6e51c2baa3acf8a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      tempMin  tempMax  cloudCover  humidity  windSpeed  visibility\n",
       "0        7.53    12.23        0.80      0.89      14.69        4.43\n",
       "1        3.58     7.15        0.62      0.79      15.04        5.64\n",
       "2       -0.61     6.54        0.31      0.84       4.48        6.20\n",
       "3       -0.63     7.59        0.78      0.85       4.35        6.22\n",
       "4        6.51    10.43        0.85      0.91       6.20        5.91\n",
       "...       ...      ...         ...       ...        ...         ...\n",
       "1790     8.55    10.57        0.96      0.85       6.80       10.00\n",
       "1791     5.79     9.40        0.87      0.85       6.82        9.03\n",
       "1792     2.30     6.67        0.40      0.79       5.15       10.00\n",
       "1793     1.08     6.14        0.18      0.76       4.85        9.11\n",
       "1794     0.42     5.69        0.55      0.72       4.79       10.00\n",
       "\n",
       "[1795 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempMin</th>\n",
       "      <th>tempMax</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>visibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.53</td>\n",
       "      <td>12.23</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.69</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.58</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.79</td>\n",
       "      <td>15.04</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.61</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4.48</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.63</td>\n",
       "      <td>7.59</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4.35</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.51</td>\n",
       "      <td>10.43</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>6.20</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>8.55</td>\n",
       "      <td>10.57</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.80</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>5.79</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.82</td>\n",
       "      <td>9.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>2.30</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5.15</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>1.08</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.76</td>\n",
       "      <td>4.85</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.42</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.72</td>\n",
       "      <td>4.79</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据处理"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b92466b03bef8597"
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T19:47:48.220347Z",
     "start_time": "2024-08-17T19:47:48.215947Z"
    }
   },
   "id": "fd2b51a1463d7e0b",
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "X = np.stack([BH_tif_400_400_after_processing, BV_tif_400_400_after_processing, CNM_tif_400_400_after_processing,\n",
    "              LAI_tif_400_400_after_processing, DSM_tif_400_400_after_processing], axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T19:47:48.998953Z",
     "start_time": "2024-08-17T19:47:48.992086Z"
    }
   },
   "id": "8c674fac3ae26795",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T19:05:17.862474Z",
     "start_time": "2024-08-17T19:05:17.858600Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "id": "ff03718762474e52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "Y = Weather_1795_6_after_processing['tempMax']",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T19:05:17.918175Z",
     "start_time": "2024-08-17T19:05:17.914443Z"
    }
   },
   "id": "cba4ce3bfed06c58",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "Y.shape",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T19:05:17.979842Z",
     "start_time": "2024-08-17T19:05:17.975755Z"
    }
   },
   "id": "ff62b6c1457a9df8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 模型构建"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "546fae4e986b1c00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:00:16.473574Z",
     "start_time": "2024-08-17T20:00:16.461914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_original = X\n",
    "Y_original = Y\n",
    "X_original.shape, Y_original.shape"
   ],
   "id": "3441766ee519ed4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 400, 5), (1795,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:00:57.722122Z",
     "start_time": "2024-08-17T20:00:57.715955Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "c187fd495036877e",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:13:38.994031Z",
     "start_time": "2024-08-17T20:13:38.849041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设置设备：GPU 如果可用，否则使用 CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "b8124fe18c9937a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:14:20.139245Z",
     "start_time": "2024-08-17T20:14:19.875935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 初始设定 n = 5\n",
    "n = 5\n",
    "seq_length = 20\n",
    "\n",
    "# 将时间序列拆分为输入序列和预测值\n",
    "def create_sequences(data, seq_length):\n",
    "    X_seq = []\n",
    "    Y_seq = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X_seq.append(data[i:i + seq_length])\n",
    "        Y_seq.append(data[i + seq_length])\n",
    "    return np.array(X_seq), np.array(Y_seq)\n",
    "\n",
    "\n",
    "# 拆分时间序列数据\n",
    "Y_seq, Y_target = create_sequences(Y_original, seq_length)\n",
    "Y_seq = np.expand_dims(Y_seq, axis=-1)  # [980, 20, 1]\n",
    "Y_target = np.expand_dims(Y_target, axis=-1)  # [980, 1]\n"
   ],
   "id": "5c25f52ded638e82",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:15:10.230810Z",
     "start_time": "2024-08-17T20:14:20.154744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 转换为 PyTorch 张量并移动到设备上\n",
    "X_land = torch.tensor(X_original, dtype=torch.float32).unsqueeze(0).repeat(Y_seq.shape[0], 1, 1, 1).to(device)\n",
    "Y_seq = torch.tensor(Y_seq, dtype=torch.float32).to(device)\n",
    "Y_target = torch.tensor(Y_target, dtype=torch.float32).to(device)"
   ],
   "id": "530a7a82815c7e00",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:15:10.498403Z",
     "start_time": "2024-08-17T20:15:10.484646Z"
    }
   },
   "cell_type": "code",
   "source": "X_land.shape, Y_seq.shape, Y_target.shape",
   "id": "24c77e1c222d2155",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1775, 400, 400, 5]),\n",
       " torch.Size([1775, 20, 1]),\n",
       " torch.Size([1775, 1]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:29.006340Z",
     "start_time": "2024-08-17T20:30:29.002321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "lr = 0.001 * batch_size / 32"
   ],
   "id": "82722d2f0da0483b",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:29.484109Z",
     "start_time": "2024-08-17T20:30:29.477731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# 数据集大小\n",
    "total_size = X_land.shape[0]\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "# 创建使用完整 X_land 的 DataLoader\n",
    "train_dataset_full, val_dataset_full = random_split(\n",
    "    TensorDataset(X_land.to(device), Y_seq.to(device), Y_target.to(device)),\n",
    "    [train_size, val_size]\n",
    ")\n",
    "\n",
    "train_loader_full = DataLoader(train_dataset_full, batch_size=batch_size, shuffle=True)\n",
    "val_loader_full = DataLoader(val_dataset_full, batch_size=batch_size)\n",
    "\n",
    "# 创建使用单独通道的 DataLoader\n",
    "channels = [0, 1, 2, 3, 4]\n",
    "train_loaders = {}\n",
    "val_loaders = {}\n",
    "\n",
    "for channel in channels:\n",
    "    X_land_channel = X_land[:, :, :, channel:channel + 1].to(device)  # 选择单个通道并移动到设备\n",
    "    train_dataset_channel, val_dataset_channel = random_split(\n",
    "        TensorDataset(X_land_channel, Y_seq.to(device), Y_target.to(device)),\n",
    "        [train_size, val_size]\n",
    "    )\n",
    "\n",
    "    train_loaders[channel] = DataLoader(train_dataset_channel, batch_size=batch_size, shuffle=True)\n",
    "    val_loaders[channel] = DataLoader(val_dataset_channel, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 结果展示\n",
    "print(\"train_loader_full length:\", len(train_loader_full))\n",
    "print(\"val_loader_full length:\", len(val_loader_full))\n",
    "\n",
    "for channel in channels:\n",
    "    print(f\"train_loader_channel_{channel} length:\", len(train_loaders[channel]))\n",
    "    print(f\"val_loader_channel_{channel} length:\", len(val_loaders[channel]))\n"
   ],
   "id": "8c4bc72bd3adfb09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader_full length: 12\n",
      "val_loader_full length: 3\n",
      "train_loader_channel_0 length: 12\n",
      "val_loader_channel_0 length: 3\n",
      "train_loader_channel_1 length: 12\n",
      "val_loader_channel_1 length: 3\n",
      "train_loader_channel_2 length: 12\n",
      "val_loader_channel_2 length: 3\n",
      "train_loader_channel_3 length: 12\n",
      "val_loader_channel_3 length: 3\n",
      "train_loader_channel_4 length: 12\n",
      "val_loader_channel_4 length: 3\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:29.878724Z",
     "start_time": "2024-08-17T20:30:29.874813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 输出dataloader的信息, 输出第一次和最后一次的信息\n",
    "def print_dataloader_info(loader):\n",
    "    for i, (land_data, temp_seq, target) in enumerate(loader):\n",
    "\n",
    "        if i == 0 or i == len(loader) - 1:\n",
    "            print(f'lenth of loader: {len(loader)}')\n",
    "            print(f'Batch {i + 1}')\n",
    "            print(f'Land Data Shape: {land_data.shape}')\n",
    "            print(f'Temporal Sequence Shape: {temp_seq.shape}')\n",
    "            print(f'Target Shape: {target.shape}')\n",
    "            print()"
   ],
   "id": "7d7e010063aa900e",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:30.227787Z",
     "start_time": "2024-08-17T20:30:30.214165Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_info(train_loader_full)",
   "id": "b4fd341baa5cb56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of loader: 12\n",
      "Batch 1\n",
      "Land Data Shape: torch.Size([128, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([128, 20, 1])\n",
      "Target Shape: torch.Size([128, 1])\n",
      "\n",
      "lenth of loader: 12\n",
      "Batch 12\n",
      "Land Data Shape: torch.Size([12, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([12, 20, 1])\n",
      "Target Shape: torch.Size([12, 1])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:39.672704Z",
     "start_time": "2024-08-17T20:30:39.667179Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_info(val_loader_full)",
   "id": "fe6a530877688cd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of loader: 3\n",
      "Batch 1\n",
      "Land Data Shape: torch.Size([128, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([128, 20, 1])\n",
      "Target Shape: torch.Size([128, 1])\n",
      "\n",
      "lenth of loader: 3\n",
      "Batch 3\n",
      "Land Data Shape: torch.Size([99, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([99, 20, 1])\n",
      "Target Shape: torch.Size([99, 1])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:41.882177Z",
     "start_time": "2024-08-17T20:30:39.706038Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_info(train_loaders[0])",
   "id": "1c25e72bed10b0a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of loader: 12\n",
      "Batch 1\n",
      "Land Data Shape: torch.Size([128, 400, 400, 1])\n",
      "Temporal Sequence Shape: torch.Size([128, 20, 1])\n",
      "Target Shape: torch.Size([128, 1])\n",
      "\n",
      "lenth of loader: 12\n",
      "Batch 12\n",
      "Land Data Shape: torch.Size([12, 400, 400, 1])\n",
      "Temporal Sequence Shape: torch.Size([12, 20, 1])\n",
      "Target Shape: torch.Size([12, 1])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:42.728254Z",
     "start_time": "2024-08-17T20:30:42.534351Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_info(val_loaders[0])",
   "id": "3055d0f3ea6e78fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of loader: 3\n",
      "Batch 1\n",
      "Land Data Shape: torch.Size([128, 400, 400, 1])\n",
      "Temporal Sequence Shape: torch.Size([128, 20, 1])\n",
      "Target Shape: torch.Size([128, 1])\n",
      "\n",
      "lenth of loader: 3\n",
      "Batch 3\n",
      "Land Data Shape: torch.Size([99, 400, 400, 1])\n",
      "Temporal Sequence Shape: torch.Size([99, 20, 1])\n",
      "Target Shape: torch.Size([99, 1])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:42.795777Z",
     "start_time": "2024-08-17T20:30:42.792256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 输出一个dataloader每批次的最值\n",
    "def print_dataloader_min_max(loader):\n",
    "    for i, (land_data, temp_seq, target) in enumerate(loader):\n",
    "        print(f'Batch {i + 1}')\n",
    "        print(f'Land Data Min: {land_data.min():.4f}, Max: {land_data.max():.4f}')\n",
    "        print(f'Temporal Sequence Min: {temp_seq.min():.4f}, Max: {temp_seq.max():.4f}')\n",
    "        print(f'Target Min: {target.min():.4f}, Max: {target.max():.4f}')\n",
    "        print()"
   ],
   "id": "ba54632d0b36e90f",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:52.983650Z",
     "start_time": "2024-08-17T20:30:42.916178Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_min_max(train_loader_full)",
   "id": "9faece4a6b8fa214",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 28.9900\n",
      "Target Min: -1.3900, Max: 30.3600\n",
      "\n",
      "Batch 2\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: 0.1800, Max: 30.3600\n",
      "Target Min: 0.9800, Max: 28.7800\n",
      "\n",
      "Batch 3\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 0.9800, Max: 26.7200\n",
      "\n",
      "Batch 4\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -0.7900, Max: 30.3600\n",
      "Target Min: 0.1800, Max: 26.0900\n",
      "\n",
      "Batch 5\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.8600, Max: 23.9200\n",
      "\n",
      "Batch 6\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.2800, Max: 25.7000\n",
      "\n",
      "Batch 7\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.9700, Max: 23.9900\n",
      "\n",
      "Batch 8\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 0.8100, Max: 25.3400\n",
      "\n",
      "Batch 9\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 0.0200, Max: 28.9900\n",
      "\n",
      "Batch 10\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -0.7900, Max: 30.3600\n",
      "Target Min: -0.7900, Max: 25.9900\n",
      "\n",
      "Batch 11\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.2200\n",
      "Target Min: 1.4300, Max: 26.5100\n",
      "\n",
      "Batch 12\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 28.9900\n",
      "Target Min: 3.2100, Max: 23.6700\n",
      "\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:56.189514Z",
     "start_time": "2024-08-17T20:30:52.999700Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_min_max(val_loader_full)",
   "id": "80d8a86118fe2f4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 1.5800, Max: 25.6700\n",
      "\n",
      "Batch 2\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.4100, Max: 30.2200\n",
      "\n",
      "Batch 3\n",
      "Land Data Min: -5.0161, Max: 1470306.5000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.2200\n",
      "Target Min: 1.2200, Max: 28.8200\n",
      "\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:57.578961Z",
     "start_time": "2024-08-17T20:30:56.254127Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_min_max(train_loaders[0])",
   "id": "9cd991ddc7ee5ced",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: -0.7900, Max: 28.7800\n",
      "\n",
      "Batch 2\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 28.9900\n",
      "Target Min: 0.9800, Max: 23.9000\n",
      "\n",
      "Batch 3\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -0.7900, Max: 30.3600\n",
      "Target Min: -1.3900, Max: 30.2200\n",
      "\n",
      "Batch 4\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -0.7900, Max: 30.3600\n",
      "Target Min: 3.1600, Max: 26.7200\n",
      "\n",
      "Batch 5\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.0100, Max: 30.3600\n",
      "\n",
      "Batch 6\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.2200\n",
      "Target Min: 0.1800, Max: 28.9900\n",
      "\n",
      "Batch 7\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.2800, Max: 28.8200\n",
      "\n",
      "Batch 8\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.0800, Max: 24.5000\n",
      "\n",
      "Batch 9\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 1.6100, Max: 25.9900\n",
      "\n",
      "Batch 10\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.5100, Max: 26.6600\n",
      "\n",
      "Batch 11\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -0.7900, Max: 30.2200\n",
      "Target Min: 2.7300, Max: 24.8900\n",
      "\n",
      "Batch 12\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: 0.1800, Max: 28.9900\n",
      "Target Min: 3.9300, Max: 18.5600\n",
      "\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:57.858472Z",
     "start_time": "2024-08-17T20:30:57.642395Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_min_max(val_loaders[0])",
   "id": "76d8687ddcec4b1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 2.7900, Max: 25.6600\n",
      "\n",
      "Batch 2\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 30.3600\n",
      "Target Min: 0.0200, Max: 26.5100\n",
      "\n",
      "Batch 3\n",
      "Land Data Min: 0.0000, Max: 343.0000\n",
      "Temporal Sequence Min: -1.3900, Max: 26.7200\n",
      "Target Min: 0.8100, Max: 23.5700\n",
      "\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:57.939553Z",
     "start_time": "2024-08-17T20:30:57.936574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ],
   "id": "1c17d02ce9b7a8b8",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:58.072205Z",
     "start_time": "2024-08-17T20:30:58.064044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义CNN特征提取器和LSTM模型\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(128 * 50 * 50, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.reshape(-1, 128 * 50 * 50)\n",
    "        x = torch.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class LSTMWithSpatialFeatures(nn.Module):\n",
    "    def __init__(self, seq_length, in_channels=1):\n",
    "        super(LSTMWithSpatialFeatures, self).__init__()  # 确保最开始调用 super().__init__()\n",
    "        # 判断是否使用CNN\n",
    "        if in_channels > 0:\n",
    "            self.use_cnn = True\n",
    "            self.cnn = CNNFeatureExtractor(in_channels=in_channels)\n",
    "            lstm_input_size = 128 + 1  # CNN输出的128维特征 + 1维时间序列数据\n",
    "        else:\n",
    "            self.use_cnn = False\n",
    "            lstm_input_size = 1  # 只有时间序列数据，没有CNN输出\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_size, hidden_size=128, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, land_data, temp_seq):\n",
    "        if self.use_cnn:\n",
    "\n",
    "            # 调整输入形状为 [batch_size, in_channels, height, width]\n",
    "            land_data = land_data.permute(0, 3, 1,\n",
    "                                          2)  # 之前的形状 [batch_size, 400, 400, 4] -> 新形状 [batch_size, 4, 400, 400]\n",
    "\n",
    "            cnn_out = self.cnn(land_data)\n",
    "            # 经过 CNN 处理后\n",
    "            # land_data -> [batch_size, 4, 400, 400]\n",
    "            # CNN 的输出 cnn_out -> [batch_size, 128]  # 经过卷积和全连接层后，输出为 128 维的特征向量\n",
    "\n",
    "            cnn_out = cnn_out.unsqueeze(1).repeat(1, temp_seq.size(1), 1)\n",
    "            # 在第二个维度（时间步长维度）增加一个维度，然后沿着这个维度重复\n",
    "            # cnn_out -> [batch_size, 1, 128] -> [batch_size, seq_length, 128]  # 这里 seq_length = temp_seq.size(1)\n",
    "\n",
    "            combined_input = torch.cat((cnn_out, temp_seq), dim=2)\n",
    "            # 将 CNN 输出的特征向量和温度序列数据结合\n",
    "            # temp_seq -> [batch_size, seq_length, 1]\n",
    "            # combined_input -> [batch_size, seq_length, 128 + 1] -> [batch_size, seq_length, 129]\n",
    "        else:\n",
    "            combined_input = temp_seq\n",
    "            # combined_input -> [batch_size, seq_length, 1]  只有时间序列数据\n",
    "\n",
    "        lstm_out, _ = self.lstm(combined_input)\n",
    "        # 经过 LSTM 层处理\n",
    "        # combined_input -> [batch_size, seq_length, 129]\n",
    "        # lstm_out -> [batch_size, seq_length, 128]  # LSTM 的输出是 128 维的特征向量        \n",
    "\n",
    "        output = self.fc(lstm_out[:, -1, :])\n",
    "        # 取 LSTM 最后一层输出，并通过全连接层进行预测\n",
    "        # lstm_out[:, -1, :] -> [batch_size, 128]\n",
    "        # output -> [batch_size, 1]  # 最终输出一个标量，表示下一时间步长的预测值\n",
    "\n",
    "        return output\n"
   ],
   "id": "57ddfe5a08b6b11e",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:58.191260Z",
     "start_time": "2024-08-17T20:30:58.184710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练和验证函数\n",
    "def train_and_evaluate(model, train_loader, val_loader, num_epochs=10):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    val_losses = []\n",
    "\n",
    "    # 在CUDA上启用AMP（混合精度）\n",
    "    scaler = torch.amp.GradScaler() if device.type == 'cuda' else None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'----------Epoch {epoch + 1}/{num_epochs}----------')\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        print('----------Training----------')\n",
    "        for i, (land_data, temp_seq, target) in enumerate(train_loader):\n",
    "            land_data, temp_seq, target = land_data.to(device), temp_seq.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 使用新的 AMP API 的 autocast\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                output = model(land_data, temp_seq)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "            if scaler:\n",
    "                # 使用混合精度缩放梯度\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # 正常的反向传播\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # output = model(land_data, temp_seq)\n",
    "            # loss = criterion(output, target)\n",
    "            # \n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            print(f'EPOCH {epoch + 1} / {num_epochs} - Batch {i + 1} / {len(train_loader)} - Loss: {loss.item()}')\n",
    "        print(f'Training Loss: {train_loss / len(train_loader)}')\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        print('----------Validation----------')\n",
    "        with torch.no_grad():\n",
    "            for i, (land_data, temp_seq, target) in enumerate(val_loader):\n",
    "                land_data, temp_seq, target = land_data.to(device), temp_seq.to(device), target.to(device)\n",
    "\n",
    "                with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                    output = model(land_data, temp_seq)\n",
    "                    loss = criterion(output, target)\n",
    "                    \n",
    "                # output = model(land_data, temp_seq)\n",
    "                # loss = criterion(output, target)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                print(f'EPOCH {epoch + 1} / {num_epochs} - Batch {i + 1} / {len(val_loader)} - Loss: {loss.item()}')\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        print(f'Validation Loss: {avg_val_loss}')\n",
    "\n",
    "    return val_losses"
   ],
   "id": "6feec6193c4703c0",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:58.328333Z",
     "start_time": "2024-08-17T20:30:58.326024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 比较不同模型的函数\n",
    "specific_indices = None"
   ],
   "id": "461dbae2c6312665",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:58.350827Z",
     "start_time": "2024-08-17T20:30:58.347382Z"
    }
   },
   "cell_type": "code",
   "source": "num_epochs = 10",
   "id": "336b3706aa43e271",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:58.481243Z",
     "start_time": "2024-08-17T20:30:58.478899Z"
    }
   },
   "cell_type": "code",
   "source": "results = {}",
   "id": "213a1b7bfb1dd794",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:30:58.515617Z",
     "start_time": "2024-08-17T20:30:58.502781Z"
    }
   },
   "cell_type": "code",
   "source": "print_dataloader_info(train_loader_full)",
   "id": "ab061903f394a03e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenth of loader: 12\n",
      "Batch 1\n",
      "Land Data Shape: torch.Size([128, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([128, 20, 1])\n",
      "Target Shape: torch.Size([128, 1])\n",
      "\n",
      "lenth of loader: 12\n",
      "Batch 12\n",
      "Land Data Shape: torch.Size([12, 400, 400, 5])\n",
      "Temporal Sequence Shape: torch.Size([12, 20, 1])\n",
      "Target Shape: torch.Size([12, 1])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:33:17.995648Z",
     "start_time": "2024-08-17T20:31:09.005153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# Baseline\n",
    "print(\"Training baseline model...\")\n",
    "model_baseline = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=0).to(device)  # 无空间数据\n",
    "results[\"Baseline\"] = train_and_evaluate(model_baseline, train_loader_full, val_loader_full, num_epochs=num_epochs)\n",
    "print(f\"Baseline MSE: {results['Baseline']}\")"
   ],
   "id": "ab97d2562fca8ddc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline model...\n",
      "----------Epoch 1/10----------\n",
      "----------Training----------\n",
      "EPOCH 1 / 10 - Batch 1 / 12 - Loss: 202.85379028320312\n",
      "EPOCH 1 / 10 - Batch 2 / 12 - Loss: 188.559814453125\n",
      "EPOCH 1 / 10 - Batch 3 / 12 - Loss: 189.0365447998047\n",
      "EPOCH 1 / 10 - Batch 4 / 12 - Loss: 185.1868438720703\n",
      "EPOCH 1 / 10 - Batch 5 / 12 - Loss: 199.2738037109375\n",
      "EPOCH 1 / 10 - Batch 6 / 12 - Loss: 191.90138244628906\n",
      "EPOCH 1 / 10 - Batch 7 / 12 - Loss: 212.84677124023438\n",
      "EPOCH 1 / 10 - Batch 8 / 12 - Loss: 171.71160888671875\n",
      "EPOCH 1 / 10 - Batch 9 / 12 - Loss: 156.16856384277344\n",
      "EPOCH 1 / 10 - Batch 10 / 12 - Loss: 146.76942443847656\n",
      "EPOCH 1 / 10 - Batch 11 / 12 - Loss: 133.90585327148438\n",
      "EPOCH 1 / 10 - Batch 12 / 12 - Loss: 95.92738342285156\n",
      "Training Loss: 172.84514872233072\n",
      "----------Validation----------\n",
      "EPOCH 1 / 10 - Batch 1 / 3 - Loss: 116.70357513427734\n",
      "EPOCH 1 / 10 - Batch 2 / 3 - Loss: 109.55708312988281\n",
      "EPOCH 1 / 10 - Batch 3 / 3 - Loss: 113.35489654541016\n",
      "Validation Loss: 113.20518493652344\n",
      "----------Epoch 2/10----------\n",
      "----------Training----------\n",
      "EPOCH 2 / 10 - Batch 1 / 12 - Loss: 93.533935546875\n",
      "EPOCH 2 / 10 - Batch 2 / 12 - Loss: 99.72116088867188\n",
      "EPOCH 2 / 10 - Batch 3 / 12 - Loss: 78.86305236816406\n",
      "EPOCH 2 / 10 - Batch 4 / 12 - Loss: 63.40400695800781\n",
      "EPOCH 2 / 10 - Batch 5 / 12 - Loss: 78.7544937133789\n",
      "EPOCH 2 / 10 - Batch 6 / 12 - Loss: 52.95333480834961\n",
      "EPOCH 2 / 10 - Batch 7 / 12 - Loss: 53.43272399902344\n",
      "EPOCH 2 / 10 - Batch 8 / 12 - Loss: 49.00518035888672\n",
      "EPOCH 2 / 10 - Batch 9 / 12 - Loss: 41.5374641418457\n",
      "EPOCH 2 / 10 - Batch 10 / 12 - Loss: 49.51344299316406\n",
      "EPOCH 2 / 10 - Batch 11 / 12 - Loss: 43.14469528198242\n",
      "EPOCH 2 / 10 - Batch 12 / 12 - Loss: 87.16911315917969\n",
      "Training Loss: 65.91938368479411\n",
      "----------Validation----------\n",
      "EPOCH 2 / 10 - Batch 1 / 3 - Loss: 34.99860382080078\n",
      "EPOCH 2 / 10 - Batch 2 / 3 - Loss: 36.00718688964844\n",
      "EPOCH 2 / 10 - Batch 3 / 3 - Loss: 33.85774612426758\n",
      "Validation Loss: 34.95451227823893\n",
      "----------Epoch 3/10----------\n",
      "----------Training----------\n",
      "EPOCH 3 / 10 - Batch 1 / 12 - Loss: 34.23070526123047\n",
      "EPOCH 3 / 10 - Batch 2 / 12 - Loss: 28.30997085571289\n",
      "EPOCH 3 / 10 - Batch 3 / 12 - Loss: 29.56439971923828\n",
      "EPOCH 3 / 10 - Batch 4 / 12 - Loss: 26.10729217529297\n",
      "EPOCH 3 / 10 - Batch 5 / 12 - Loss: 28.102054595947266\n",
      "EPOCH 3 / 10 - Batch 6 / 12 - Loss: 28.916118621826172\n",
      "EPOCH 3 / 10 - Batch 7 / 12 - Loss: 31.07406234741211\n",
      "EPOCH 3 / 10 - Batch 8 / 12 - Loss: 24.806331634521484\n",
      "EPOCH 3 / 10 - Batch 9 / 12 - Loss: 22.312950134277344\n",
      "EPOCH 3 / 10 - Batch 10 / 12 - Loss: 24.966957092285156\n",
      "EPOCH 3 / 10 - Batch 11 / 12 - Loss: 34.66576385498047\n",
      "EPOCH 3 / 10 - Batch 12 / 12 - Loss: 14.294764518737793\n",
      "Training Loss: 27.2792809009552\n",
      "----------Validation----------\n",
      "EPOCH 3 / 10 - Batch 1 / 3 - Loss: 25.68995475769043\n",
      "EPOCH 3 / 10 - Batch 2 / 3 - Loss: 30.93798828125\n",
      "EPOCH 3 / 10 - Batch 3 / 3 - Loss: 25.695287704467773\n",
      "Validation Loss: 27.441076914469402\n",
      "----------Epoch 4/10----------\n",
      "----------Training----------\n",
      "EPOCH 4 / 10 - Batch 1 / 12 - Loss: 25.557289123535156\n",
      "EPOCH 4 / 10 - Batch 2 / 12 - Loss: 34.59046173095703\n",
      "EPOCH 4 / 10 - Batch 3 / 12 - Loss: 30.242294311523438\n",
      "EPOCH 4 / 10 - Batch 4 / 12 - Loss: 30.310972213745117\n",
      "EPOCH 4 / 10 - Batch 5 / 12 - Loss: 32.533958435058594\n",
      "EPOCH 4 / 10 - Batch 6 / 12 - Loss: 26.5275936126709\n",
      "EPOCH 4 / 10 - Batch 7 / 12 - Loss: 28.468727111816406\n",
      "EPOCH 4 / 10 - Batch 8 / 12 - Loss: 28.970417022705078\n",
      "EPOCH 4 / 10 - Batch 9 / 12 - Loss: 30.747108459472656\n",
      "EPOCH 4 / 10 - Batch 10 / 12 - Loss: 24.852529525756836\n",
      "EPOCH 4 / 10 - Batch 11 / 12 - Loss: 29.931358337402344\n",
      "EPOCH 4 / 10 - Batch 12 / 12 - Loss: 41.972740173339844\n",
      "Training Loss: 30.392120838165283\n",
      "----------Validation----------\n",
      "EPOCH 4 / 10 - Batch 1 / 3 - Loss: 25.204782485961914\n",
      "EPOCH 4 / 10 - Batch 2 / 3 - Loss: 30.195880889892578\n",
      "EPOCH 4 / 10 - Batch 3 / 3 - Loss: 25.18487548828125\n",
      "Validation Loss: 26.861846288045246\n",
      "----------Epoch 5/10----------\n",
      "----------Training----------\n",
      "EPOCH 5 / 10 - Batch 1 / 12 - Loss: 23.47945785522461\n",
      "EPOCH 5 / 10 - Batch 2 / 12 - Loss: 32.571895599365234\n",
      "EPOCH 5 / 10 - Batch 3 / 12 - Loss: 29.111793518066406\n",
      "EPOCH 5 / 10 - Batch 4 / 12 - Loss: 23.67578125\n",
      "EPOCH 5 / 10 - Batch 5 / 12 - Loss: 25.307327270507812\n",
      "EPOCH 5 / 10 - Batch 6 / 12 - Loss: 31.738346099853516\n",
      "EPOCH 5 / 10 - Batch 7 / 12 - Loss: 25.195512771606445\n",
      "EPOCH 5 / 10 - Batch 8 / 12 - Loss: 31.7441463470459\n",
      "EPOCH 5 / 10 - Batch 9 / 12 - Loss: 23.224655151367188\n",
      "EPOCH 5 / 10 - Batch 10 / 12 - Loss: 24.07229995727539\n",
      "EPOCH 5 / 10 - Batch 11 / 12 - Loss: 27.953624725341797\n",
      "EPOCH 5 / 10 - Batch 12 / 12 - Loss: 22.143735885620117\n",
      "Training Loss: 26.68488136927287\n",
      "----------Validation----------\n",
      "EPOCH 5 / 10 - Batch 1 / 3 - Loss: 26.028213500976562\n",
      "EPOCH 5 / 10 - Batch 2 / 3 - Loss: 29.359745025634766\n",
      "EPOCH 5 / 10 - Batch 3 / 3 - Loss: 25.523136138916016\n",
      "Validation Loss: 26.970364888509113\n",
      "----------Epoch 6/10----------\n",
      "----------Training----------\n",
      "EPOCH 6 / 10 - Batch 1 / 12 - Loss: 18.299884796142578\n",
      "EPOCH 6 / 10 - Batch 2 / 12 - Loss: 30.44491958618164\n",
      "EPOCH 6 / 10 - Batch 3 / 12 - Loss: 29.346233367919922\n",
      "EPOCH 6 / 10 - Batch 4 / 12 - Loss: 29.55547332763672\n",
      "EPOCH 6 / 10 - Batch 5 / 12 - Loss: 24.517187118530273\n",
      "EPOCH 6 / 10 - Batch 6 / 12 - Loss: 25.82264518737793\n",
      "EPOCH 6 / 10 - Batch 7 / 12 - Loss: 31.57584571838379\n",
      "EPOCH 6 / 10 - Batch 8 / 12 - Loss: 24.140892028808594\n",
      "EPOCH 6 / 10 - Batch 9 / 12 - Loss: 25.482770919799805\n",
      "EPOCH 6 / 10 - Batch 10 / 12 - Loss: 25.267776489257812\n",
      "EPOCH 6 / 10 - Batch 11 / 12 - Loss: 28.2443790435791\n",
      "EPOCH 6 / 10 - Batch 12 / 12 - Loss: 25.941625595092773\n",
      "Training Loss: 26.553302764892578\n",
      "----------Validation----------\n",
      "EPOCH 6 / 10 - Batch 1 / 3 - Loss: 25.592330932617188\n",
      "EPOCH 6 / 10 - Batch 2 / 3 - Loss: 28.87635612487793\n",
      "EPOCH 6 / 10 - Batch 3 / 3 - Loss: 25.11845588684082\n",
      "Validation Loss: 26.52904764811198\n",
      "----------Epoch 7/10----------\n",
      "----------Training----------\n",
      "EPOCH 7 / 10 - Batch 1 / 12 - Loss: 23.055591583251953\n",
      "EPOCH 7 / 10 - Batch 2 / 12 - Loss: 25.26763153076172\n",
      "EPOCH 7 / 10 - Batch 3 / 12 - Loss: 24.42123031616211\n",
      "EPOCH 7 / 10 - Batch 4 / 12 - Loss: 24.40750503540039\n",
      "EPOCH 7 / 10 - Batch 5 / 12 - Loss: 24.844501495361328\n",
      "EPOCH 7 / 10 - Batch 6 / 12 - Loss: 25.850744247436523\n",
      "EPOCH 7 / 10 - Batch 7 / 12 - Loss: 26.488298416137695\n",
      "EPOCH 7 / 10 - Batch 8 / 12 - Loss: 23.255653381347656\n",
      "EPOCH 7 / 10 - Batch 9 / 12 - Loss: 29.352319717407227\n",
      "EPOCH 7 / 10 - Batch 10 / 12 - Loss: 25.4879207611084\n",
      "EPOCH 7 / 10 - Batch 11 / 12 - Loss: 30.97133445739746\n",
      "EPOCH 7 / 10 - Batch 12 / 12 - Loss: 16.00045394897461\n",
      "Training Loss: 24.950265407562256\n",
      "----------Validation----------\n",
      "EPOCH 7 / 10 - Batch 1 / 3 - Loss: 23.58940887451172\n",
      "EPOCH 7 / 10 - Batch 2 / 3 - Loss: 27.600849151611328\n",
      "EPOCH 7 / 10 - Batch 3 / 3 - Loss: 23.333444595336914\n",
      "Validation Loss: 24.84123420715332\n",
      "----------Epoch 8/10----------\n",
      "----------Training----------\n",
      "EPOCH 8 / 10 - Batch 1 / 12 - Loss: 24.014263153076172\n",
      "EPOCH 8 / 10 - Batch 2 / 12 - Loss: 25.628122329711914\n",
      "EPOCH 8 / 10 - Batch 3 / 12 - Loss: 30.240942001342773\n",
      "EPOCH 8 / 10 - Batch 4 / 12 - Loss: 24.843345642089844\n",
      "EPOCH 8 / 10 - Batch 5 / 12 - Loss: 20.571109771728516\n",
      "EPOCH 8 / 10 - Batch 6 / 12 - Loss: 24.743465423583984\n",
      "EPOCH 8 / 10 - Batch 7 / 12 - Loss: 26.88394546508789\n",
      "EPOCH 8 / 10 - Batch 8 / 12 - Loss: 21.70136260986328\n",
      "EPOCH 8 / 10 - Batch 9 / 12 - Loss: 24.167753219604492\n",
      "EPOCH 8 / 10 - Batch 10 / 12 - Loss: 19.868209838867188\n",
      "EPOCH 8 / 10 - Batch 11 / 12 - Loss: 27.517597198486328\n",
      "EPOCH 8 / 10 - Batch 12 / 12 - Loss: 17.447856903076172\n",
      "Training Loss: 23.968997796376545\n",
      "----------Validation----------\n",
      "EPOCH 8 / 10 - Batch 1 / 3 - Loss: 22.405048370361328\n",
      "EPOCH 8 / 10 - Batch 2 / 3 - Loss: 26.055511474609375\n",
      "EPOCH 8 / 10 - Batch 3 / 3 - Loss: 22.119333267211914\n",
      "Validation Loss: 23.526631037394207\n",
      "----------Epoch 9/10----------\n",
      "----------Training----------\n",
      "EPOCH 9 / 10 - Batch 1 / 12 - Loss: 27.68606185913086\n",
      "EPOCH 9 / 10 - Batch 2 / 12 - Loss: 23.378887176513672\n",
      "EPOCH 9 / 10 - Batch 3 / 12 - Loss: 25.01369285583496\n",
      "EPOCH 9 / 10 - Batch 4 / 12 - Loss: 22.820091247558594\n",
      "EPOCH 9 / 10 - Batch 5 / 12 - Loss: 19.222476959228516\n",
      "EPOCH 9 / 10 - Batch 6 / 12 - Loss: 23.742534637451172\n",
      "EPOCH 9 / 10 - Batch 7 / 12 - Loss: 24.087444305419922\n",
      "EPOCH 9 / 10 - Batch 8 / 12 - Loss: 24.457990646362305\n",
      "EPOCH 9 / 10 - Batch 9 / 12 - Loss: 22.677276611328125\n",
      "EPOCH 9 / 10 - Batch 10 / 12 - Loss: 16.900611877441406\n",
      "EPOCH 9 / 10 - Batch 11 / 12 - Loss: 17.656139373779297\n",
      "EPOCH 9 / 10 - Batch 12 / 12 - Loss: 14.890350341796875\n",
      "Training Loss: 21.87779649098714\n",
      "----------Validation----------\n",
      "EPOCH 9 / 10 - Batch 1 / 3 - Loss: 19.890090942382812\n",
      "EPOCH 9 / 10 - Batch 2 / 3 - Loss: 23.212459564208984\n",
      "EPOCH 9 / 10 - Batch 3 / 3 - Loss: 19.683746337890625\n",
      "Validation Loss: 20.928765614827473\n",
      "----------Epoch 10/10----------\n",
      "----------Training----------\n",
      "EPOCH 10 / 10 - Batch 1 / 12 - Loss: 15.675707817077637\n",
      "EPOCH 10 / 10 - Batch 2 / 12 - Loss: 20.769136428833008\n",
      "EPOCH 10 / 10 - Batch 3 / 12 - Loss: 18.791332244873047\n",
      "EPOCH 10 / 10 - Batch 4 / 12 - Loss: 21.12769889831543\n",
      "EPOCH 10 / 10 - Batch 5 / 12 - Loss: 15.686851501464844\n",
      "EPOCH 10 / 10 - Batch 6 / 12 - Loss: 17.972652435302734\n",
      "EPOCH 10 / 10 - Batch 7 / 12 - Loss: 28.652854919433594\n",
      "EPOCH 10 / 10 - Batch 8 / 12 - Loss: 19.85861587524414\n",
      "EPOCH 10 / 10 - Batch 9 / 12 - Loss: 19.226551055908203\n",
      "EPOCH 10 / 10 - Batch 10 / 12 - Loss: 17.10039520263672\n",
      "EPOCH 10 / 10 - Batch 11 / 12 - Loss: 16.469831466674805\n",
      "EPOCH 10 / 10 - Batch 12 / 12 - Loss: 37.43852233886719\n",
      "Training Loss: 20.73084584871928\n",
      "----------Validation----------\n",
      "EPOCH 10 / 10 - Batch 1 / 3 - Loss: 17.096961975097656\n",
      "EPOCH 10 / 10 - Batch 2 / 3 - Loss: 19.850360870361328\n",
      "EPOCH 10 / 10 - Batch 3 / 3 - Loss: 16.808013916015625\n",
      "Validation Loss: 17.918445587158203\n",
      "Baseline MSE: [113.20518493652344, 34.95451227823893, 27.441076914469402, 26.861846288045246, 26.970364888509113, 26.52904764811198, 24.84123420715332, 23.526631037394207, 20.928765614827473, 17.918445587158203]\n",
      "CPU times: total: 1min 3s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T20:33:26.223697Z",
     "start_time": "2024-08-17T20:33:26.218142Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "789b23a2a046fcde",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baseline': [113.20518493652344,\n",
       "  34.95451227823893,\n",
       "  27.441076914469402,\n",
       "  26.861846288045246,\n",
       "  26.970364888509113,\n",
       "  26.52904764811198,\n",
       "  24.84123420715332,\n",
       "  23.526631037394207,\n",
       "  20.928765614827473,\n",
       "  17.918445587158203]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# Baseline + n种所有空间数据\n",
    "print(f\"\\nTraining baseline + all {n} spatial features model...\")\n",
    "model_baseline_n = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=n).to(device)\n",
    "results[f\"Baseline + all {n} features\"] = train_and_evaluate(model_baseline_n, train_loader_full, val_loader_full,\n",
    "                                                             num_epochs=num_epochs)\n",
    "print(f\"Baseline + all {n} features MSE: {results[f'Baseline + all {n} features']}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-17T20:35:27.923684Z",
     "start_time": "2024-08-17T20:34:08.307348Z"
    }
   },
   "id": "c146335f0e32528",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training baseline + all 5 spatial features model...\n",
      "----------Epoch 1/10----------\n",
      "----------Training----------\n",
      "EPOCH 1 / 10 - Batch 1 / 12 - Loss: nan\n",
      "EPOCH 1 / 10 - Batch 2 / 12 - Loss: nan\n",
      "EPOCH 1 / 10 - Batch 3 / 12 - Loss: nan\n",
      "EPOCH 1 / 10 - Batch 4 / 12 - Loss: nan\n",
      "EPOCH 1 / 10 - Batch 5 / 12 - Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:4\u001B[0m\n",
      "Cell \u001B[1;32mIn[79], line 28\u001B[0m, in \u001B[0;36mtrain_and_evaluate\u001B[1;34m(model, train_loader, val_loader, num_epochs)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m scaler:\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;66;03m# 使用混合精度缩放梯度\u001B[39;00m\n\u001B[0;32m     27\u001B[0m     scaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 28\u001B[0m     scaler\u001B[38;5;241m.\u001B[39mstep(optimizer)\n\u001B[0;32m     29\u001B[0m     scaler\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;66;03m# 正常的反向传播\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\amp\\grad_scaler.py:454\u001B[0m, in \u001B[0;36mGradScaler.step\u001B[1;34m(self, optimizer, *args, **kwargs)\u001B[0m\n\u001B[0;32m    448\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munscale_(optimizer)\n\u001B[0;32m    450\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[0;32m    451\u001B[0m     \u001B[38;5;28mlen\u001B[39m(optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    452\u001B[0m ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo inf checks were recorded for this optimizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 454\u001B[0m retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_opt_step(optimizer, optimizer_state, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    456\u001B[0m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstage\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m OptState\u001B[38;5;241m.\u001B[39mSTEPPED\n\u001B[0;32m    458\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\amp\\grad_scaler.py:351\u001B[0m, in \u001B[0;36mGradScaler._maybe_opt_step\u001B[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_maybe_opt_step\u001B[39m(\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    345\u001B[0m     optimizer: torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mOptimizer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    349\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[0;32m    350\u001B[0m     retval: Optional[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 351\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28msum\u001B[39m(v\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[0;32m    352\u001B[0m         retval \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\amp\\grad_scaler.py:351\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_maybe_opt_step\u001B[39m(\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    345\u001B[0m     optimizer: torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mOptimizer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    349\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[0;32m    350\u001B[0m     retval: Optional[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 351\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28msum\u001B[39m(v\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[0;32m    352\u001B[0m         retval \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "2ad21d7828f57823",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Baseline + 单个空间数据",
   "id": "6706d2f445d04ee0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseline + BH 层\n",
    "model_baseline_BH = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=1).to(device)"
   ],
   "id": "d96e038ef46144a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "results[f\"Baseline + feature BH\"] = train_and_evaluate(model_baseline_BH, train_loaders[0], val_loaders[0],\n",
    "                                                       num_epochs=num_epochs)"
   ],
   "id": "4877ca206b6ffaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "313d856a378a74b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseline + BV 层\n",
    "model_baseline_BV = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=1).to(device)"
   ],
   "id": "5ba8911f640108ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "results[f\"Baseline + feature BV\"] = train_and_evaluate(model_baseline_BV, train_loaders[1], val_loaders[1],\n",
    "                                                       num_epochs=num_epochs)"
   ],
   "id": "f8db84cea3c1fec8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "ffaf116a62ca81ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseline + CNM 层\n",
    "model_baseline_CNM = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=1).to(device)"
   ],
   "id": "4bcc016cdbd837e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "results[f\"Baseline + feature CNM\"] = train_and_evaluate(model_baseline_CNM, train_loaders[2], val_loaders[2],\n",
    "                                                        num_epochs=num_epochs)"
   ],
   "id": "5b29e17e3f54dbf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "7c109e23e3de2792",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseline + LAI 层\n",
    "model_baseline_LAI = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=1).to(device)"
   ],
   "id": "ccf29648fa52aad4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "results[f\"Baseline + feature LAI\"] = train_and_evaluate(model_baseline_LAI, train_loaders[3], val_loaders[3],\n",
    "                                                        num_epochs=num_epochs)"
   ],
   "id": "8bbdcbeefe5e8bd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "112cb6ca09c28955",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseline + DSM 层\n",
    "model_baseline_DSM = LSTMWithSpatialFeatures(seq_length=seq_length, in_channels=1).to(device)"
   ],
   "id": "409a01f2f42f7257",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "results[f\"Baseline + feature DSM\"] = train_and_evaluate(model_baseline_DSM, train_loaders[4], val_loaders[4],\n",
    "                                                        num_epochs=num_epochs)"
   ],
   "id": "f15dfd94c8de60c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "results",
   "metadata": {
    "collapsed": false
   },
   "id": "691803927ea2d784",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 储存results\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('Results/RF_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "    "
   ],
   "id": "ea872b1259dfa804",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 模型名称\n",
    "model_names = list(results.keys())\n",
    "\n",
    "# 模型结果\n",
    "model_results = [results[model_name] for model_name in model_names]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "name_print = [\"Baseline\", \"B + 5 layers\", \"B + BH\", \"B + BV\", \"B + CNM\", \"B + LAI\", \"B + DEM\"]\n",
    "\n",
    "# 绘制条形图\n",
    "plt.bar(name_print, model_results, color='skyblue')\n",
    "\n",
    "# 倾斜45度显示模型名称\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 条形图上显示数值\n",
    "for i, result in enumerate(model_results):\n",
    "    plt.text(i, result + 0.01, f\"{result:.4f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Model Comparison')\n",
    "plt.show()\n"
   ],
   "id": "96f1219bf9dda8df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "445ac573c20d19cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
